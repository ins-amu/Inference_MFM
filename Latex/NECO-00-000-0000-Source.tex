\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{times}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow}
%
\usepackage[authoryear]{natbib}
%
\usepackage{rotating}
\usepackage{bbm}
\usepackage{latexsym}

\usepackage{url}
\usepackage{hyperref}
\usepackage{booktabs}
%\DeclareGraphicsExtensions{.eps,.png}

%%% margins 
\textheight 23.4cm
\textwidth 14.65cm
\oddsidemargin 0.375in
\evensidemargin 0.375in
\topmargin  -0.55in
%
\renewcommand{\baselinestretch}{2}
%
\interfootnotelinepenalty=10000
%
\renewcommand{\thesubsubsection}{\arabic{section}.\arabic{subsubsection}}
\newcommand{\myparagraph}[1]{\ \\{\em #1}.\ \ }
\newcommand{\citealtt}[1]{\citeauthor{#1},\citeyear{#1}}
\newcommand{\myycite}[1]{\citep{#1}}

% Different font in captions
\newcommand{\captionfonts}{\normalsize}

\makeatletter  
\long\def\@makecaption#1#2{%
  \vskip\abovecaptionskip
  \sbox\@tempboxa{{\captionfonts #1: #2}}%
  \ifdim \wd\@tempboxa >\hsize
    {\captionfonts #1: #2\par}
  \else
    \hbox to\hsize{\hfil\box\@tempboxa\hfil}%
  \fi
  \vskip\belowcaptionskip}
\makeatother   
%%%%%

\renewcommand{\thefootnote}{\normalsize \arabic{footnote}} 	

\begin{document}
\hspace{13.9cm}1

\ \vspace{20mm}\\

{\LARGE Inference on the Macroscopic Dynamics of Spiking Neurons}

\ \\
{\bf \large Nina Baldy$^{\displaystyle 1}$, Martin Breyton$^{\displaystyle 1}$, Marmaduke M. Woodman$^{\displaystyle 1}$, Viktor K. Jirsa$^{\displaystyle 1, \displaystyle *, \displaystyle \dag}$, Meysam Hashemi$^{\displaystyle 1, \displaystyle *, \displaystyle \dag}$} \\
{$^{\displaystyle 1}$Aix Marseille Univ, INSERM, INS, Inst Neurosci Syst, Marseille, France.} \\
{$^{\displaystyle *}$Corresponding author.} \\
{$^{\displaystyle \dag}$These authors contributed equally.}\\
%

%\ \\[-2mm]
{\bf Keywords:} Spiking neurons, mean-field models, inference, deep neural networks, system dynamics

\thispagestyle{empty}
\markboth{}{NC instructions}
%
\ \vspace{-0mm}\\
%
%Abstract
\begin{center} {\bf Abstract} \end{center}
The process of inference on networks of spiking neurons is essential to decipher the underlying mechanisms of brain computation and function. In this study, we conduct inference on parameters and dynamics of a mean-field approximation, simplifying the interactions between neurons. Estimating parameters of this class of generative model allows one to predict the system's dynamics and responses under changing inputs and, indeed, changing parameters. We first assume a set of known state-space equations, and address the problem of inferring the lumped parameters from observed time series. Crucially, we consider this problem in the setting of bistability, random fluctuations in system dynamics, and partial observations, in which some states are hidden. To identify the most efficient estimation or inversion scheme in this particular system identification, we benchmark against state-of-the-art optimization and Bayesian estimation algorithms, highlighting their strengths and weaknesses. Additionally, we explore how well the statistical relationships between parameters are maintained across different scales. We found that deep neural density estimators outperform other algorithms in the inversion scheme, despite potentially resulting in overestimated uncertainty and correlation between parameters. Nevertheless, this issue can be improved by incorporating time-delay embedding. We then eschew the mean-field approximation and employ deep Neural ODEs on spiking neurons, illustrating prediction of system dynamics and vector fields from microscopic states. Overall, this study affords an opportunity to predict brain dynamics and responses to various perturbations or pharmacological interventions using deep neural networks.
%%%%%%%%%%%

%
\ \vspace{-0mm}\\
%
{\bf Abbreviations:} MF, Mean-Field; QIF, Quadratic Integrate-and-Fire; SBI, Simulation-Based Inference;  SNPE, Sequential Neural Posterior Estimation; MCMC, Markov Chain Monte Carlo; HMC, Hamiltonian Monte Carlo; MAP, Maximum a Posteriori; DE, Differential Evolution; PSO, Particle Swarm Optimization; BO, Bayesian Optimization; ODEs, Ordinary Differential Equations; SDEs, Stochastic Differential Equations; Neural ODEs, Neural Ordinary Differential Equations.

\section{Introduction}
\label{Introduction}

Neural computation involves the complex information processing performed by spiking neurons, where their interactions within neural circuits contribute to higher-level computations and cognitive functions. Consequently, the cornerstone of theoretical neuroscience lies in the use of mathematical models to understand the intricacies of neural computation \citep{Dayan2005, Hertz2018}. This approach enables researchers to explore the complexities of neural processes, thereby revealing insights into the mechanisms that drive brain function and behavior. These mathematical models can range from simple idealized representations of single neurons \citep{Hopfield1982, Izhikevich2003} to complex network models that simulate the interactions within neural circuits \citep{Marder1998, Sussillo2014, Leary2015,  Bittner2021}. 
The biological neural computation forms the basis for the brain's ability to execute various inference tasks, such as recognizing patterns, making decisions, and generating responses to stimuli. This capability relies on the collective behavior of spiking neurons, where the interactions and coordination among these neurons within neural circuits enable the brain to process, integrate, and interpret sensory information, ultimately leading to higher-level cognitive functions and adaptive behavior \citep{Kandel2000, Gerstner2014, Friston2009, Friston2017}. 


Mean-Field (MF) models serve as effective computational abstractions that represent the collective behavior of large populations of neurons, while maintaining a degree of mathematical tractability \citep{Amari1977, Wilson1973, Jirsa1996, David2003, Deco2008, Hutt2015, Coombes2018, Bandyopadhyay2021, Cook2022}. Hence,  MF models facilitate the study of information processing and computation within the brain, which underlie cognitive processes such as perception, memory, and learning. Nevertheless, deriving and validating MF models from spiking neural networks present many challenges, particularly when assessing how the interaction between individual neurons and parameters leads to macroscopic behavior that aligns with the averaged activity of neural populations.


Recently, an analytically-driven MF model of spiking neurons has been formulated, which can effectively describe all potential macroscopic dynamical states of the network, including states of synchronous spiking activity \citep{Montbrio_Pazo_Roxin}. However, the operation of such complex systems (governed by coupled nonlinear differential equations) is determined by the selection of (biological or phenomenological) parameters, which when set in a specific configuration, give rise to a measurable signature of a computation \citep{Achard2006, Sussillo2014}. Analyzing MF models and comparing their emergent dynamics against a network of neurons involves solving inverse problems to ascertain the optimal parameter setting. This process requires swift and robust outcomes to inform real-time decisions and also to deal with observation and dynamical noise. Yet, even in the simplest models, there can be a degenerate relationship between the model parameters and its overall emergent function \citep{Edelman2001, Prinz2004, Alonso2019}, making the inverse problem more challenging. 

Maintaining the inter-dependency between parameters by traversing across scales adds an additional layer of complexity to the validation process. It is crucial to distinguish between genuine, biologically relevant correlations, and artificial correlations that may arise from the inference process or modeling assumptions. Furthermore, due to the intricate nature of computation within neural circuits, it becomes intractable to analytically derive MF models that include more biological realism (such as adaption, neuromodulation, extra-synaptic transmission, and  E/I ratios). Statistical inference offers an efficient and adaptable approach to solving the inverse problem by identifying approximate parameter distributions that are responsible for generating computations in a biologically realistic model \citep{Achard2006, Liepe2014, Lueckmann2017, Goncalves2020, Bittner2021, Mlynarski2021}. 


The performance of statistical inference algorithms depends on the task, and there is no universally best algorithm for different inverse problems. Therefore, we conducted a benchmarking analysis against state-of-the-art optimization and Bayesian estimation algorithms to discern their respective advantages and limitations.
In practice, optimization methods are commonly used to quickly determine unknown quantities through a single point estimate \citep{Mendes1998, Nocedal1999, Kelley1999, Floudas2009}. These methods involve iteratively adjusting parameters to minimize or maximize an objective function, scoring the model's performance against observed data (e.g., through minimizing distance errors or maximizing correlation; \cite{Banga2008, Tashkova2011, Svensson2012, Hashemi2018}). 


The Bayesian approach offers a principled method for making inferences, predictions, establishing relationships between parameters, and quantifying uncertainty in the decision-making process \citep{BDA, Bishop, Gelman2020, VanSchoot2021}. In Bayesian modeling, all model parameters are treated as random variables and their values are subject to variation based on their underlying probability distributions. Such probabilistic techniques provide the full posterior distribution of unknown quantities hidden in the underlying data generating process. The uncertainty and inter-dependency in Bayesian estimation are naturally quantified by assigning a probability distribution to each parameter (known as the prior distribution), which is then updated based on the information provided by the data (referred to as the likelihood function). To conduct a fully Bayesian procedure, the state-of-the-art MCMC method is adaptive Hamiltonian Monte Carlo (HMC; \cite{Duane1987, Neal2010, Hoffman2014}), which utilizes gradient information to avoid random walk behavior.  This enables efficient sampling from high-dimensional distributions that may exhibit strong correlations \citep{Betancourt2017}.



Simulation-Based Inference (SBI; \cite{Cranmer2020, Brehmer2021}) or likelihood-free inference \citep{Papamakarios2016,  Brehmer2020} leverages deep generative models to conduct approximate Bayesian estimation, using low-dimensional data features that are generated by random simulations \citep{Goncalves2020, Lueckmann2021, Boelts2022}. In this efficient approach, a simple base probability distribution (prior) is transformed into a more complex distribution (posterior), through a sequence of invertible transformations (i.e., Normalizing Flows; \cite{Rezende2015, Papamakarios2019}). Notably, it allows for direct estimation of joint posterior distributions, bypassing the need for MCMC sampling \citep{Greenberg2019, Papamakarios2019b}. Moreover, expressive deep generative models have the potential to capture parameter nonlinear relationships between parameters and multi-modalities in the distributions \citep{Hashemi2023}.


Data-driven methods for learning dynamical models from time-series data have been extensively researched for several decades \citep{Juang1994, Ljung1998, Brunton2016, Linderman2017, Duncker2019, Koppe2019, Sip2023}.
Instead of relying on discretized maps, Neural Ordinary Differential Equations (Neural ODEs; \cite{Chen2018}) form a new family of deep neural network models for modeling continuous-time dynamics. Neural ODEs define the vector fields and ODE solution as a black-box differential equation solver, allowing for uncovering the dynamics of a system even when the governing equations are unknown \citep{Dupont2019, Bilovs2021}. This data-driven approach involves parameterizing system dynamics as continuous functions, enabling smooth and uninterrupted modeling of temporal evolution \citep{Yan2019, Kim2021}. Neural ODEs naturally adapt to varying time intervals and can accommodate fluctuations in the frequency of data observations \citep{Zhu2022, Goyal2023}.


Through an exploration of the aforementioned methods, we demonstrate that global optimization algorithms, such as Differential Evolution algorithm, offer fast and accurate point estimation of the true generative parameters when the dynamical noise is absent. However, when dealing with dynamic evolution that are subject to noise, SBI using deep neural density estimators emerges as the superior approach, outperforming other algorithms, such as adaptive HMC sampling. Additionally, when dealing with missing data (such as population firing rate) in state-space modeling, HMC fails to capture the dynamics of bistable switching behaviour. Instead, SBI is able to accurately recover the diverse dynamics in the phase-space representation. Nevertheless, this approach may lead to an overestimation of uncertainty and correlation between parameters, which can be mitigated by using time-delay embedding technique to improve the results. We validate this by employing a MF model of quadratic integrate-and-fire (QIF) neurons, which demonstrates that the inter-dependencies between parameters are maintained when traversing across scales. Finally, we demonstrate that training deep Neural ODEs on spiking neurons enables the inference of vector fields at macroscopic level. This allows for the prediction of emergent behaviors and system dynamics based on the microscopic state of the spiking neurons. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Materials and methods}
\label{Methods}

\subsection{\textcolor{black}{Macroscopic description of} spiking neurons}

The quadratic integrate-and-fire (QIF) neurons are a class of simplified computational models that are extensively used to study the dynamics of spiking neurons \citep{Gerstner2002, Izhikevich2007}. In the QIF model, the membrane potential of \textcolor{black}{each} neuron evolves according to a quadratic differential equation until it reaches a threshold, at which point the neuron emits a spike and the potential is reset.

\cite{Montbrio_Pazo_Roxin} have proposed a MF model that accurately describes macroscopic states of populations of firing neurons. This mechanistic model derives the firing rate equations for networks of heterogeneous, all-to-all coupled QIF neurons, which is exact in the thermodynamic limit, i.e. for large numbers of neurons. Specifically, when considering specific distributions of heterogeneity, the Lorentzian ansatz yields a nonlinear system of two ordinary differential equations for the firing rate $r$ and mean membrane potential $v$ of the neuronal population:
\begin{subequations}
\begin{align}
    \dot{r} &= 2 r v +\Delta/\pi  \label{eq:mpr_r} \\
    \dot{v} &= v^2 - \pi^2 r^2 + J r + \eta+ I(t) \label{eq:mpr_v}
\end{align}
\label{eq:mpr}
\end{subequations}
where $\eta$ is the average excitability, $J$ denotes the synaptic weight, and $\Delta$ indicates the spread of the neuronal excitability distribution in the neural population. Depending on the parameter settings \textcolor{black}{and exogenous input current I(t)}, the phase diagram exhibits three qualitatively distinct regions: a single stable node, which represents a low-activity state; a single stable focus (spiral), which generally corresponds to a high-activity state; and a region of bistability, where both low and high firing rates can coexist (see \autoref{fig:MPR_Istep_phaseplanes}). This model has succeeded in establishing an exact correspondence between the time evolution of firing rate of the network and the underlying microscopic state of the spiking neurons \citep{Montbrio_Pazo_Roxin}.


\subsection{Inference methods}

We validate the mean-field approximation by comparing it against detailed spiking neurons, using various parameter estimation inference methods. To evaluate these methods, we use synthetic data generated from the MF model and a network of QIF neurons.
Inference methods investigated in this work can be broadly divided into two classes:

(i) Optimization methods that return a point estimate of best fit based on the minimizing of a cost function, such as chi-squared error criterion defined by 
\begin{equation}
\label{eq:khi}
{\chi^2}({\theta})= \sum\limits_{i=1}^{N_t} \left({\hat x}(t_i, \theta)-{x}(t_i)\right)^2,
\end{equation}
where $x(t_{i})$ denotes the observed data at time points $t_i$ with $ i \in \{1, 2, \dots, N_t\}$, and ${\hat x}(t_i,{ \theta})$ represents the corresponding model prediction. Here $\theta \in \{ \eta, J, \Delta \}$ is the set of unknown parameters, and the set of observation combines activity of both $r$, $v$ (unless it is missing). Assuming no prior information and a Gaussian likelihood function with uncorrelated noise, this casts as a Maximum Likelihood Estimation (MLE) problem \citep{Hashemi2018}.

(ii) Bayesian methods return a posterior distribution of parameters, $ p(\theta \mid x)$, which represents an ensemble of parameter sets that are plausible given the observed data. Given the data $x$ and model parameters $\theta$, Bayes rule defines the posterior distribution as
\begin{equation}
    p(\theta \mid x) = \frac{p(\theta) p(x \mid \theta)}{p(x)}. \label{eq:Bayes_rule}
\end{equation}
The prior information $p(\theta)$ is typically determined before seeing the data (through beliefs and previous evidence). The likelihood function $p(x \mid \theta)$ represents the probability of some observed outcomes given a certain set of parameters (the information provided by the observed data). The denominator $p(x)=\int p(x \mid \theta)p(\theta)d\theta$ represents the model evidence or marginal likelihood, which amounts to simply a normalization factor.


From the optimization methods, we use the global search algorithms that incorporate a bio-inspired random search principle: Differential Evolution (DE; \cite{Storn1997, Price1999}), and Particle Swarm Optimization (PSO; \cite{Kennedy1995, Eberhart1995}). These algorithms do not require an initial guess for the parameters or the gradient information of the objective function. We also consider Bayesian Optimization (BO; \cite{Snoek2012, Shahriari2015}), an algorithm that constructs a probabilistic model for the objective function using Gaussian processes. This approach allows for the integration of uncertainty in the optimization process.


From the Bayesian methods, we compare the results of two state-of-the-art Bayesian computation algorithms: Hamiltonian Monte Carlo (HMC; \cite{Duane1987, Neal2010}) which is unbiased and exact in infinite runs, and a Simulation-Based Inference (SBI; \cite{Cranmer2020, Brehmer2021}) which approximates \textcolor{black}{(or parameterized)} the posterior using deep generative models. Here, generative modeling is an unsupervised machine learning method to model a probability distribution based on the samples drawn from that distribution.  From the Bayesian methods, we also report the results of Maximum a Posteriori (MAP) estimation. 



\subsection{Hamiltonian Monte Carlo}

Markov Chain Monte Carlo (MCMC) is a powerful class of computational algorithms used for sampling from a distribution, in which the sampling process does not require knowledge of the entire distribution, making it a versatile tool. \citep{Andrieu2003, Murphy2022, Mcelreath2020}. MCMC is unbiased and asymptotically exact, in the limit of infinite runs. Hamiltonian Monte Carlo (HMC; \cite{Duane1987, Neal2010}) is a gradient-based MCMC designed to avoid random walk behaviour, and it can efficiently sample from high-dimensional distributions that may exhibit strong correlations \citep{Betancourt2017}. However, the efficiency of HMC is sensitive to the algorithm parameters. 

In this study we use a self-tuning variant of HMC (known as the No-U-Turn Sampler; \cite{Hoffman2014}) from a high-level statistical modeling tool called Stan \citep{Carpenter2017}.
In particular, the NUTS calibrates the number of steps and step-size of the leapfrog integrator (in solving the Hamiltonian equations of motion) during a warm-up phase to achieve a target Metropolis acceptance rate. For more details see \cite{Betancourt2013, Baldy2023}. Moreover, Stan offers alternative methods such as MAP estimation using L-BFGS optimization, automatic differentiation for efficient gradient computation, and various diagnostics to assess the convergence of the inference process (see \url{https://mc-stan.org}). 



\subsection{Simulation-Based Inference}

Simulation-Based Inference (SBI) conducts efficient Bayesian inference for complex models when the calculation of the likelihood function is either analytically or computationally intractable \citep{Cranmer2020, Brehmer2021}.
In computational models, where the data can be generated through stochastic simulations, SBI leverages repeated simulations from the generative model and employs probabilistic machine learning to estimate a target probability distribution. Instead of directly sampling from distributions using MCMC or explicitly evaluating the likelihood function, SBI overcomes these challenges by using deep neural density estimators, such as Masked Autoregressive Flows (MAF; \cite{Papamakarios2017}).  These density estimators learn an invertible transformation between the distributions of parameters and low-dimensional data features at a very low computational cost, to efficiently sample from distributions. 

Taking the prior distribution $p(\theta)$ over the parameters $\theta$, a limited number of $N$ simulations are generated for training step from the generative model i.e.,  $\{(\theta_i, x_i)\}_{i=1}^{N} \sim p(\theta, x)$. After the training step, we are able to quickly estimate the approximated posterior $q_{\phi}(\theta \mid x)$ with learnable parameters $\phi$, so that for the observed data $x_{obs}$: $q_{\phi}(\theta \mid x_{obs}) \simeq p(\theta \mid x_{obs})$. For more details see \cite{Goncalves2020, Hashemi2023}. 
\textcolor{black}{Minimizing the Kullback-Leibler divergence between the parameterized (approximate) posterior and the true posterior is also the objective in Dynamical Causal Modeling \citep{Friston2003, Blei2017}, which is based on maximizing a lower bound on the marginal likelihood of the data, or equivalently, minimizing the free energy.}

The methods for SBI often include a sequential training procedure, which adaptively guides simulations to yield more informative estimates \citep{Papamakarios2019b, Lueckmann2019, Durkan2020, Wiqvist2021, Deistler2022}. In particular, Sequential Neural Posterior Estimation (SNPE; \cite{Greenberg2019, Goncalves2020})  dynamically refines the proposals, network weights, and posterior estimates to learn the relationships between model parameters and the observed summary statistics of the data. In this study, we used SNPE with a single round to take advantage of an amortized strategy; After incurring an initial computational cost for the simulation and training steps to learn all the joint posterior distributions, then the posterior can be quickly estimated from any new observations (by a forward pass through neural networks)  without any additional computational overhead or further simulations.



\subsection{Time-delay embedding}

Time-delay embedding is a commonly used technique for characterizing dynamical systems based on limited measurements, time-series analysis, and prediction \citep{Takens2006}. In time-delay embedding, the reconstruction of a latent high-dimensional system relies on incorporating incomplete measurements along with a temporal history of preceding measurements to create a comprehensive representation \citep{Kennel1992, Hirsh2021}.
In a subsequent analysis, we challenge the inference process by assuming that the firing rate activity $r$ is not directly observed (missing data problem). Instead, to improve the inference, we recovered the latent time-series $r_{rec}$ from the observed activity $v$, which is coupled to $r$ according to Eq.~\ref{eq:mpr}.
By expanding on a method introduced by \cite{Abarbanel}, which primarily focuses on predicting physical variables in time-delay embedding, we removed the assumption that we have the access to training data points from the hidden time-series. Instead, we leverage our understanding of the generator to simulate data pairs $(r, v)$ that can be used for training purposes.

Time-delay embedding requires the setting of hyperparameters, such as the delay (time lag), $T$, and  the dimension of the embedding space, $d$. These hyperparameters are typically set prior to training, often based on the minimization of mutual information to determine the appropriate delay and the false nearest neighbors method to determine the number of embedding dimensions \citep{Kennel1992, Tan2023}. However, in the present application, we have found that the hyperparameters suggested by these methods were not the most effective in achieving an accurate fit. Instead, we select hyperparameters that minimize the mean square error of the fit to simulated data, with $T=160$ points (i.e., $0.16~sec$) and $d=12$. To do this, a set of 100 pairs of coupled time-series $(r, v)$ was simulated, with an observation noise intensity of 0.1 and varying parameters ($\Delta, \eta, J$). These pairs were then used to infer regression coefficients that closely match $r$ to the delay embedding space representation of $v$.



\subsection{Neural ODEs}

Neural ODEs are a set of machine learning techniques that allow to reconstruct the phase-space of a dynamical system from a training set of observations \citep{Chen2018}. In a first analysis, we trained a Neural ODE on time-series from the MF model, and then applied the same method to the data generated by a network of QIF spiking neurons. If $\textbf{x}(t)$ is the vector of state variables governed by the dynamical system $\dot{\textbf{x}} = f(\textbf{x}, \theta,I_{ext})$, one can use a Neural ODE to approximate the function $f$ with an artificial neural network $F_{\phi}$, yielding the corresponding dynamical equation $\dot{\hat{\textbf{x}}} = F_{\phi}(\hat{\textbf{x}},\theta,I_{ext})$. $F_{\phi}$ is learned through backpropagation, minimizing the loss function for each training example of length $T$: 
\[L_{\phi}(\hat{x},x)={\sum_{t=0}^{T}(\hat{x}(t, \theta)-x(t))^2}\]
where $\hat{x}$ and $x$ are times-series generated by $F_{\phi}$ and $f$,  respectively, with the same integration scheme (e.g., Heun's method). In this study, a Neural ODE was implemented in JAX \citep{jax2018github} by constructing a multi-layer-perceptron (MLP) with one hidden layer of 16 units, and with hyperbolic tangeant activation functions. The cost function was the average loss functions across training examples $\mathcal{L_{\phi}}=\frac{1}{N T}\sum_{n=1}^{N}L_{\phi,n}$. 
At each training iteration, the initial $(r, v)$ values of each segment is fed to the Neural ODEs and the forecast trajectory according to current state of the $F_{\phi}$ enters the cost function, then minimized through backpropagation using the Adam optimizer. 



\subsection{Software and algorithmic setup} 

We use Python implementations of the optimization and Bayesian algorithms: DE from SciPy \citep{Virtanen2020scipy}, PSO from the toolkit PySwarms \citep{Miranda2018pyswarms}, and BO from the package Bayesian Optimization \citep{Nogueira2014BO}. DE is set with population size of 10, and the maximum iterations of 500. PSO is set with 10 particles, and 500 iterations. BO is set with 50 random initialisation, 500 iterations, and kappa=100 (higher values increase exploration).

The MAP estimation is obtained using a quasi-Newton L-BFGS optimizer from Python interface to Stan \citep{Carpenter2017}, an open-source probabilistic programming language for Bayesian modeling and statistical inference. We also use Stan's implementation of the NUTS for fully Bayesian estimation by HMC, with Metropolis acceptance rate of 0.8, maximum tree depth of 10, warm-up iterations of 1000, and 500 sampling phase iterations. 

Finally, for SBI we used SNPE from the PyTorch-based SBI toolkit \citep{Tejero2020sbi}. SNPE was run for a single round with 100,000 simulations, unless specified otherwise. For training step, we used a MAF, with 5 autoregressive layers, each with two hidden layers of 50 units.
The set of data features includes the statistical moments of time-series up to the fourth order (mean, standard deviation, skewness, and kurtosis), and the peak properties (number and location of first peak, as shown in \autoref{fig:DataFeatures}).


Parameter bounds for optimization, and  uniform prior for Bayesian inference, were set as: $\Delta \in [0.1, 5]$, $\eta \in [-10, -3]$, $J \in [5, 20]$. For the simulation of Eq.~\ref{eq:mpr}, we used Euler-Maruyama integration for $t=100~sec$ with a time step of $dt=1~msec$. The ground truth parameters were set as $\eta=-4.6$, $J=14.5$, and $\Delta=0.7$, ensuring that the system is in a bistable regime, unless specified otherwise, \textcolor{black}{with} a \textcolor{black}{one-}step current with amplitude of $3~v$ \textcolor{black}{applied} from time $30~sec$ to \textcolor{black}{time} $60~sec$. \textcolor{black}{The input current was considered known and not included in the inferred quantities, unless otherwise specified.} Each simulation took around $0.01~sec$ to run using a Just-In-Time (JIT) compiler. To generate stochastic dynamics, a zero-mean Gaussian noise with $\sigma=0.1$ was added to the both $r$, and $v$ variables. The prior on dynamical noise was set as $\sigma \in [0, 1]$.
For comparison with the MF model, we ran a network of $10^4$ all-to-all connected QIF neurons using the Brian simulator \citep{Stimberg2019}.
 
The model simulation and parameter estimation were performed on a Linux machine with 3.60 GHz Intel Core i7-7700 and 8 GB of memory.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{Results}

We present the results of the optimization and Bayesian algorithms for three cases: (i) inferring from exact deterministic synthetic data, (ii) inferring from stochastic synthetic data driven by dynamical \textcolor{black}{(a.k.a. state)} noise, and (iii) inferring with stochastic synthetic data when the activity for $r$ is unknown (missing data).  We report and compare the goodness-of-fit using the root mean square error (RMSE) to the true (observed or hidden) time-series and parameters, the variance in the estimation process, and the computational cost.


Before running inference process, we conduct a sensitivity analysis to assess the structural identifiability of the parameters. This analysis involves calculating local sensitivity coefficients, which measure the effect of small adjustments in a parameter on the model's output while keeping all other parameters constant. A small change in a sensitive parameter leads to a significant alteration in the model output, indicating its identifiability. Conversely, when there are no alterations in the model output despite adjustments in a parameter, it suggests the parameter's non-identifiability. To assess the identifiability of the parameters, we used the profile likelihood \citep{Raue2009, Wieland2021} and Hessian matrix, a metric describing the local curvature of a function based on its second partial derivatives \citep{Hashemi2018, Hashemi2023}. Our results indicate that all three parameters $\Delta$, $\eta$, and $J$ can be identifiable, however, the profile likelihood obtained using Eq.~\ref{eq:khi} reveals the presence of numerous local minima (see \autoref{fig:SensitivityAnalysis}). This highlights the difficulty in attaining the global minimum during the inference process.


\subsection{Inference on deterministic data}

\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.1.eps}
    \caption{Inference on deterministic data.  
     (\textbf{A}) The trajectories in phase-plane exhibiting bistable dynamics, and the corresponding time-series of firing rate ($r$) and membrane potential ($v$), used as the observations for inference (ground truth: $\Delta=0.7$, $\eta=-4.6$, $J=14.5$). (\textbf{B}) The estimated trajectories in phase-plane, along with the corresponding parameters displayed in the top panels. All the algorithms capture the bistable dynamics in a qualitative manner. (\textbf{C}) For parameters $\Delta$, $\eta$, and $J$, the point estimations are displayed in the top panels along with the profile likelihood (in grey), while the full posterior distributions are shown in the bottom panels. \textcolor{black}{The colors are matched to the corresponding algorithms in panel \textbf{B}, and vertical black lines show the true values used to generate the data.} HMC leads to more precise parameter estimates with lower uncertainty compared to SBI.  (\textbf{D}) Accuracy in estimation based on the sum over RMSE values. The bootstrap uncertainty is calculated for time-series (top panel) and parameters (bottom panel) through multiple runs. (\textbf{E}) Computational cost for each inference algorithm.  Overall, DE excels in both speed and accuracy, but it offers only a point estimate. HMC is exact and provides informative posterior estimates, but it is very computationally prohibitive. Rather, SBI effectively provides accurate estimates along with associated uncertainties at a reasonable computational cost. DE: Differential Evolution; PSO: Particle Swarm Optimization; BO: Bayesian Optimization; MAP, Maximum a Posteriori; HMC: Hamiltonian Monte Carlo;  SBI: Simulation-Based Inference; RMSE: Root Mean Square Error.
    } 
    \label{fig:ODEdata}
\end{figure}


Here, we compare the inference results of different algorithms when we have complete observations of both state variables $(r,v)$, and the system operates without any noise (see \autoref{fig:ODEdata}). The observed time-series and trajectories in phase-plane, which exhibit a bistability between a stable node and a stable focus\textcolor{black}{, driven by the input current}, are illustrated in \autoref{fig:ODEdata}\textbf{A}. From the results demonstrated in \autoref{fig:ODEdata}\textbf{B}, it can be seen that all the algorithms qualitatively reproduce the bistability behaviour in the phase-plane. However, when evaluating their performance by estimating the true generative parameters, all optimization methods, except DE, get stuck in a local minima (\autoref{fig:ODEdata}\textbf{C}). The results indicate that DE, SBI and HMC algorithms correctly recover the ground-truth parameters, the former as an almost exact point estimate (\autoref{fig:ODEdata}\textbf{C}, top panels), while the latter two, SBI and HMC, yield full posterior distributions (\autoref{fig:ODEdata}\textbf{C}, bottom panels).  In terms of uncertainty quantification, HMC offers a slightly more informative posterior distribution compared to SBI (see \autoref{fig:ODE_joint_posterior}).

When it comes to matching the observed time-series, the optimization algorithms such as PSO and BO deviate significantly from true values, while other approaches equally retrieve an almost perfect fit to the observed time-series (see \autoref{fig:ODEdata}\textbf{D}, top panel). Nevertheless, MAP largely fails to accurately estimate model parameters due to overfitting (\autoref{fig:ODEdata}\textbf{D}, bottom panel). This type of overfitting emphasizes the importance of quantifying uncertainty to verify the reliability of inference, going beyond a point estimation. Note that for HMC and SBI, we report the results using posterior predictive check i.e., re-generating data using random parameters drawn from the estimated posterior and then comparing simulations with the observed data.

In terms of computational cost for inference, DE has a clear advantage with its rapid performance, typically taking less than a minute to complete (\autoref{fig:ODEdata}\textbf{E}). Despite a high precision, the computational cost of HMC in this example is prohibitively expensive, taking almost a hundred hours to complete the inference process. On the other hand, SBI was terminated in nearly one and a half hours (including 100k random simulations, training, and sampling), making it approximately 60 orders of magnitude faster than HMC. Additionally, due to the amortized approach adopted by SBI, each sampling process takes less than one minute to estimate the joint posterior distributions from new data. 

In summary, DE demonstrates superior speed and accuracy, but it only provides a point estimate. Among Bayesian methods, HMC is exact and provides certain estimates, but it is computationally prohibitive. On the other hand, SBI effectively provides accurate estimates along with associated uncertainties at a reasonable computational cost (see~\autoref{tab:ODEdata}). 


\subsection{Inference on stochastic data}

The inherent randomness in stochastic systems introduces uncertainty into the behavior of the system under study, which makes it challenging to accurately identify its underlying dynamics. In particular, the presence of dynamical noise significantly increases the complexity of the inference process and necessitates the use of robust probabilistic methodologies that can effectively account for and handle the stochastic nature of the data. 


\begin{figure}[p]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.2.eps}
    \caption{Inference on stochastic data.  (\textbf{A}) The generated bistable dynamics in the phase-plane and the corresponding time-series of firing rate ($r$) and membrane potential ($v$) used as the observations for inference (ground truth: $\Delta=0.7$, $\eta=-4.6$, $J=14.5$).  (\textbf{B}) The estimated trajectories in the phase-planes, along with the corresponding parameters displayed in the top panels. All the algorithms qualitatively capture the bistable behavior. (\textbf{C}) The point estimation along with the profile likelihood (top panels) and the full posterior (bottom panels) for parameters $\Delta$, $\eta$, and $J$. \textcolor{black}{The colors are matched to the corresponding algorithms in panel \textbf{B}, and vertical black lines show the true values used to generate the data.} SBI leads to more precise parameter estimates with lower uncertainty compared to HMC. (\textbf{D}) Accuracy in estimation based on the sum over RMSE values for the time-series (top panel) and parameters (bottom panel). The bootstrap uncertainty is calculated through multiple runs. (\textbf{E}) Computational cost for each inference algorithm.  When evaluating overall accuracy, uncertainty quantification, and computational cost, then SBI outperforms all other algorithms.
    }
    \label{fig:SDEdata}
\end{figure}


Here, we report the results of inference on synthetic data with zero-centered Gaussian dynamical noise, where the intensity is $\sigma = 0.1$  (see \autoref{fig:SDEdata}).
The observed noisy time-series and trajectories in phase-plane, exhibiting a bistable behavior between a stable node and a stable focus, are illustrated in \autoref{fig:SDEdata}\textbf{A}. From the results demonstrated in \autoref{fig:SDEdata}\textbf{B}, we can see that all the algorithms qualitatively replicate the \textcolor{black}{bistable} behavior in the phase-plane. Yet, when assessing how well they recover the true parameters, only DE yields an accurate point estimate among the optimization algorithms (\autoref{fig:SDEdata}\textbf{C}, top panels). 

In terms of uncertainty quantification, SBI generates posteriors that are tightly centered on the ground-truth parameters, in comparison to the HMC sampling (see \autoref{fig:SDEdata}\textbf{C}, bottom panels, and \autoref{fig:SDE_joint_posterior}). A detailed comparison of convergence diagnostics indicates that both SBI and HMC methods provide ideal Bayesian estimation (see \autoref{fig:Zscores_Shrinkage_SDE}).
Regarding the proximity to the observed time-series and true parameters, both HMC and SBI offer a closer match compared to the other algorithms (\autoref{fig:SDEdata}\textbf{D}). This highlights the challenges inherent in inferring stochastic systems via optimization algorithms, as the error metrics such as RMSE used to define the objective function may not reliably gauge accuracy. 

In terms of computational efficiency for inference, the running time of all algorithms increases when the noise is present, except for HMC (\autoref{fig:SDEdata}\textbf{E}). Nevertheless, when considering the entire process (including random simulations, training, and sampling), SBI remains approximately 8 orders of magnitude faster than HMC. Interestingly, SBI is also able to accurately and efficiently estimate the dynamical noise in the system (see ~\autoref{fig:SBI_SDE_Istep_RV_NoiseEstimation}). 

In summary, these results demonstrate that when considering overall accuracy in the presence of noise and bistability, uncertainty quantification, and computational cost, the SBI outperforms all other algorithms, including HMC (see~\autoref{tab:SDEdata}). 


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.3.eps}
    \caption{The performance of inference algorithms with increasing the intensity of dynamical noise using the sum over: (\textbf{A}) RMSE of the time-series, and (\textbf{B}) RMSE of the model parameters. Overall, with a sufficient number of simulations for training, the SBI emerges as the most accurate and robust method in our algorithmic benchmark.
    }
    \label{fig:NoiseSweep}
\end{figure}


Next, we investigate how varying the intensity of dynamical noise impacts the inference on stochastic data. Our results indicate that the overall quality of fit to the noisy data (\autoref{fig:NoiseSweep}\textbf{A}) and the accuracy of recovered parameters (\autoref{fig:NoiseSweep}\textbf{B}) remain stable up to $\sigma \leq 10^{-1}$ for all algorithms. However, both metrics exhibit a significant increase beyond this threshold, particularly for optimization methods. 

The MAP estimation is robust with regard to the amount of dynamical noise, but it tends to overfit. This is because the MAP estimation consistently provides the least accurate inference on parameters, even though its fit to the time-series data is almost perfect. In contrast, Bayesian inference methods such as HMC and SBI are overall more accurate and significantly more robust compared to optimization methods.  Both HMC and SBI exhibit significantly lower error than others, even at high noise levels (e.g., $\sigma = 1$). 

Interestingly, SBI appears to be more resilient to high levels of noise compared to HMC. Given a sufficient number of simulations for training (e.g., 100k), SBI demonstrates the most accurate and robust fit to the data, consistently staying close to a perfect fit across various noise values. See \autoref{fig:SBI_ZandShrink} for a systematic investigation on the impact of the number of simulations on the performance of SBI.  Overall, these results indicate that SBI is the most accurate and robust algorithm in our benchmark.


\subsection{Inference on missing data in the state-space}

Here, we explore the performance of inference methods in situations where data is available for only one of the variables in the state-space modeling. We consider the mean membrane potential $v$ as the observed data, which is simulated with dynamic noise of intensity $\sigma = 0.1$, while the firing rate $r$ remains latent (\autoref{fig:Missingdata}\textbf{A}). The noise intensity is fixed for inference process.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.4.eps}
    \caption{Inference on noisy observation with missing data. The generated bistable dynamics in the phase-plane and the corresponding time-series of observed membrane potential ($v$) and hidden firing rate ($r$), with ground truth: $\Delta=0.7$, $\eta=-4.6$, $J=14.5$.  (\textbf{B}) The estimated trajectories in the phase-planes, along with the corresponding parameters displayed in the top panels. Only DE and SBI provide a close agreement with the observed bistable trajectories. (\textbf{C}) The point estimation along with the profile likelihood (top panels), and the full posterior (bottom panels) for parameters $\Delta$, $\eta$, and $J$. \textcolor{black}{The colors are matched to the corresponding algorithms in panel \textbf{B}, and vertical black lines show the true values used to generate the data.} (\textbf{D}) The accuracy of estimation is evaluated by summing the RMSE values for both the true time-series (top panel) and parameters (bottom panel),  while considering the bootstrap uncertainty through multiple iterations. (\textbf{E}) The computational cost for each inference algorithm.  Overall,  DE and SBI outperform other algorithms in inferring the bistable dynamics when dealing with missing data.
    }
    \label{fig:Missingdata}
\end{figure}

From \autoref{fig:Missingdata}\textbf{B}, we observe that only DE and SBI were capable of retrieving the true dynamics in the phase-plane when $r$ was missing. As shown in \autoref{fig:Missingdata}\textbf{C} (top panel), among optimization algorithms, only DE correctly estimates the true parameters. Notably, HMC fails considerably in this problem by proposing over-confident posterior distributions that are far from the ground truth (\autoref{fig:Missingdata}\textbf{C}, bottom panel). In contrast, the estimated posteriors using SBI are centered on the ground-truth parameters, but they exhibit a more diffuse uncertainty compared to the previous results (see \autoref{fig:SDE_missingdata_joint_posterior}).
Note that HMC fails to accurately reconstruct the latent variable $r$ from observed $v$ (see \autoref{fig:SDEmissingdata_timeseries}), even though its error on the fitted trajectories is comparable to that of SBI (\autoref{fig:Missingdata}\textbf{D}, top panel). Nevertheless, the unreliability in the results produced by HMC becomes evident when observing the RMSE values for model parameters (\autoref{fig:Missingdata}\textbf{D}, bottom panel). 

In terms of computational cost for inference (\autoref{fig:ODEdata}\textbf{E}), optimization by DE still has a clear advantage with its rapid performance.
Interestingly, SBI remains efficient, approximately 68 orders of magnitude faster than HMC (see~\autoref{tab:Missingdata}). Overall, SBI outperforms HMC in the recovery of the bistable dynamics, including the hidden firing rate.  However, this approach can lead to an overestimation in the associated uncertainty, when compared to the full observed state-space dynamics (see \autoref{fig:SDEdata} versus \autoref{fig:Missingdata}).


\subsection{Phase-space reconstruction}

As demonstrated in the previous section, the inference process posed a challenge when only the membrane potential $v$ was observed and the firing rate $r$ was missing. To improve the inference in such cases, we approximately reconstruct the hidden $r$ from the observed counterpart $v$, using the time-delay embedding technique (\autoref{fig:ReconstructedPhasePlane_and_corr}). 

As it can be seen from \autoref{fig:ReconstructedPhasePlane_and_corr}\textbf{A}, the reconstructed firing rates closely follow the original time-series (RMSE=0.151). This leads to accurately capturing the bistable switching behavior in the phase-plane, as shown in \autoref{fig:ReconstructedPhasePlane_and_corr}\textbf{B}. We subsequently explored how the access to the trajectories of state variables influences the statistical relationships between parameters. When both the firing rate ($r$) and membrane potential ($v$) are observed, both HMC and SBI algorithms reveal a strong correlation between the average excitability $\eta$, and the synaptic weight $J$ ($\rho_{\eta, J} \approx -0.78$), while the other parameters exhibit no codependency (see \autoref{fig:ReconstructedPhasePlane_and_corr}\textbf{C}). 

When the firing rate is latent and only the membrane potential is observed, the correlation between parameters is more pronounced, as estimated by HMC, while SBI tends to overestimate this co-dependency as fully degenerate (see \autoref{fig:ReconstructedPhasePlane_and_corr}\textbf{D}). This highlights the challenges in the inference or parameter estimation process when lacking access to complete knowledge of the system dynamics. This issue can be improved by using time-delay embedding to reconstruct the full phase-space dynamics and inform the inference process, as shown by the reduced correlation between parameters \textcolor{black}{in the joint Bayesian posterior} in  \autoref{fig:ReconstructedPhasePlane_and_corr}\textbf{E}. 


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.5.eps}
    \caption{Reconstruction of firing rate $r$ from mean membrane potential $v$, and comparison of inter-dependency between parameters. (\textbf{A}) Original and reconstructed mean firing rate. (\textbf{B}) Observed (left) and reconstructed (right) system dynamics in phase-plane. Correlations between estimated joint posterior distributions, using HMC (left) and SBI (right), when: (\textbf{C}) Both $r$ and $v$ are observed, (\textbf{D}) Only $v$ is observed and $r$ is hidden, (\textbf{E}) Reconstructed $r$ from the observed $v$ using time-delay embedding. }
    \label{fig:ReconstructedPhasePlane_and_corr}
\end{figure}


\subsection{Inter-dependency between generative parameters}

In the previous sections, we performed inference against the system dynamics derived from the MF model given by Eq. \eqref{eq:mpr}. We now aim to investigate how the inference of the posterior distribution and the relationships between parameters remains consistent by traversing across scales. This can be achieved by conducting inference using observed data generated by QIF neurons (at the microscopic level) versus the data generated by MF model (at the macroscopic level).

First, we compared the simulated membrane potential $v$ and firing rate $r$ using a MF model given by Eq.~\eqref{eq:mpr} to the averaged activities of a network of $10^4$ all-to-all connected QIF neurons (see raster plot shown in \autoref{fig:QIF_correlations}\textbf{A}). \autoref{fig:QIF_correlations}\textbf{B} demonstrates that the MF model can accurately generate the (smoothed) transient dynamics that emerge from an ensemble of spiking neurons. However, the first spike emitted by the MF model after stimulation may exhibit a short lag compared to the averaged QIF neurons. % why?
Then, we used the data generated by MF and QIF models as the observation, and conducted inference using the MF model through Bayesian estimation algorithms, such as HMC and SBI. Specifically, we compared the correlations between the estimated joint posteriors of model parameters in each case, as shown in \autoref{fig:QIF_correlations}(\textbf{C}). 

\begin{figure}
     \centering
     \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.6.eps}
     \caption{Comparing the transient dynamics of a MF model with the emergent dynamics of a network of QIF neurons, and exploring the interdependency between parameters. (\textbf{A}) Raster plot of QIF neurons. (\textbf{B}) The membrane potential $v$ (top panel) and firing rate $r$ (bottom panel) generated by MF model (in cyan) versus averaged activities of QIF neurons, as the raw simulations (in light gray) and smoothed (dark grey). At time $t=30~sec$, a current $I_0=3~ mv$ is applied to all neurons, and set to zero again at $t=60~sec$. (\textbf{C}) The Pearson correlation coefficients between parameters in the MF model, estimated using Bayesian algorithms (HMC and SBI), against data generated by different models (MF and QIF). The strong negative linear correlation between excitability and synaptic weight ($\rho_{\eta, J} \approx -0.78$) persists across algorithms and datasets.}
     \label{fig:QIF_correlations}
 \end{figure}
 
We observed consistent correlations between parameters across the two types of datasets (macroscopic MF and microscopic QIF) when fitted using the MF model. Our results indicate that the strong negative linear correlation between excitability and synaptic weight ($\rho_{\eta, J} \approx -0.78$) persists when using HMC and SBI against both datasets. Considering the agreement between HMC and SBI across two datasets, we can conclude that the consistent high correlation between parameters $\eta$ and $J$ is intrinsic and not induced by the inference process or model assumptions.


\subsection{SBI on the stimulus current}

Here, we challenge SBI approach in inferring system dynamics while also accounting for an unknown input current, which plays a crucial role in emerging the bistable behavior. Given only the position or waveform of input currents, we estimate the intensity or angular velocity across various ground-truth values: $I_0$ in a step current as $I(t)=I_0 \cdot \mathbf{1}_{\text{stim}}(t)$ and $\omega_0$ in a sinusoidal current as $I(t)=\sin (\omega_0 t) \cdot \mathbf{1}_{\text{stim}}(t)$, as shown in \autoref{fig:SBI_stimulus}(\textbf{A}), and (\textbf{B}), respectively. 
Our results demonstrate that in both cases, the SBI approach accurately recovers the unknown parameters in the input currents. The posterior credibility intervals, visualized as error bars, indicate certain estimates that are close to a perfect fit ($y=x$, in red) across all different values. See \autoref{fig:SBI_Timeseries_ISin_IStep} for the observed and predicted time-series. This validates the capability of SBI in accurately estimating the system dynamics, even when the characteristics of the input current are unknown.

\begin{figure}
    \centering
    \includegraphics[width=0.85\linewidth]{Figs/NECO-00-000-0000-Figure.7.eps}
    \caption{SBI on the stimulus current. (\textbf{A}) Step current as $I(t)=I_0 \cdot \mathbf{1}_{\text{stim}}(t)$. (\textbf{B}) Sinusoidal current as $I(t)=\sin (\omega_0 t) \cdot \mathbf{1}_{\text{stim}}(t)$. Dashed red line represents a perfect fit.  }
    \label{fig:SBI_stimulus}
\end{figure}


\subsection{SBI on stability of system dynamics}

Here, we show that SBI can be used to investigate the stability of system dynamics from low-dimensional summary statics of observed time-series. \autoref{fig:SBI_PhaseDiagram} shows a phase diagram of the system as a function of the mean $\eta$ and synaptic weight $J$, both normalized by the width of the input distribution $\Delta$. Using linear stability analysis, there are three qualitatively distinct regions of the phase diagram: (i) A single stable node corresponding to a low-activity state (shown in blue), (ii) A single stable focus generally corresponding to a high-activity state (shown in red), and (iii) A region of bistability between low and high firing rate (shown in cyan).  

Interestingly, a similar basin of bistability in phase diagram can be readily reproduced using deep neural density estimators (such as MAF model) in SBI approach. By training on the low-dimensional data features extracted from the time-series (such as the presence or absence of damped oscillations before, during, and after stimulation), the generated posterior samples display a very close agreement with the results obtained from linear stability analysis. This demonstrate the capability of SBI in accurately estimating system dynamics from summary statics, including the presence of bistability in the phase diagram.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.8.eps}
    \caption{SBI over the stability of system dynamics in phase diagram. In the wedge-shaped region (shaded in cyan), bistability exists between a high and a low activity state. On the right side, a stable focus is indicated (shaded in red), while on the left side, a stable node is depicted (shown in blue). By training a deep neural density estimator on data features, the posterior samples generated using SBI accurately capture the bistable dynamics (shown in yellow), aligning closely with results from linear stability analysis. The black asterisk denotes the observation point used for inference. The insets display observed (dark blue) and predicted (light blue) time-series in different regimes: (\textbf{A}) Bistability, (\textbf{B}) Stable focus, and (\textbf{C}) Stable node.}
    \label{fig:SBI_PhaseDiagram}
\end{figure}


\subsection{Neural ODEs on system dynamics}

In this section, our aim is to infer the collective dynamics of QIF neurons without making any assumptions about the underlying generating dynamics. To achieve this, we used Neural ODEs as a powerful tool for modeling continuous-time dynamics without assuming any prior knowledge of the underlying equations governing the system. Unlike traditional discrete-time models, Neural ODEs parameterize the continuous-depth formulation, allowing for seamless interpolation between observed data points.

We first validate Neural ODEs using the data garnered by MF model described by Eq.~\eqref{eq:mpr}.  We generated 3 different datasets using the MF model given by Eq.~\eqref{eq:mpr}, with a set of parameters corresponding to a bistable regime: $\{\Delta=1,J=15,\eta=-5\}$. For each datasets, we sampled the phase-space by varying initial conditions according to a regular grid so that $r_0\in[0.1, 3]$ and $v_0\in[-2,2]$. We then solved the system for 1000 time points (with an integration time step of $dt=0.01~sec$). To speed up training, each trajectory was downsampled by a factor of 10 and divided into 10 segments, each consisting of 10 time points. The training and test data were randomly split, with $75\%$ of the data used for training and $25\%$ used for testing. 

The first training set, comprising of $N=100$ deterministic trajectories, was generated (see \autoref{fig:NeuralODE_montbrio}\textbf{A}). The results indicate that the Neural ODE almost perfectly reconstructed the phase-space (see \autoref{fig:NeuralODE_montbrio}\textbf{B}). In the second training set, which had the same size, a dynamical noise with a standard deviation of $\sigma=0.1$ was added during the integration process (\autoref{fig:NeuralODE_montbrio}\textbf{C}). In this case, the estimated nullclines suffered from overfitting although without affecting the overall reconstructed dynamics, as the predicted trajectories were still very similar to the original data  (as shown \autoref{fig:NeuralODE_montbrio}\textbf{D}). Increasing the size of the training dataset (see \autoref{fig:NeuralODE_montbrio}\textbf{E}) significantly reduces overfitting.  As a result, the reconstructed nullclines show a very close agreement with those obtained from the deterministic data (\autoref{fig:NeuralODE_montbrio}\textbf{F}).
To illustrate overfitting, \autoref{fig:NeuralODEs_Fit_traces_MPR} shows the loss functions for the different scenarios, as well as snapshots of phase-space reconstruction during training. Overall, the Neural ODE successfully reconstructs the underlying deterministic system, even in the presence of noise.

\begin{figure}
    \centering
    \includegraphics[width=0.99\linewidth]{Figs/NECO-00-000-0000-Figure.9.eps}
    \caption{Exemplary observed phase-space in a bistable regime (top row), and the reconstructed phase-space by Neural ODE (bottom row). The trajectories are displayed after the 10-fold split, without the downsampling step for better visualization. Corresponding fit obtained with the Neural ODE for the same initial conditions and estimated phase-plane (bottom row) after 45000 training iterations. Either (\textbf{A}, \textbf{B}) using a training set of 100 deterministic trajectories, (\textbf{C}, \textbf{D}) using a training set with dynamical noise, (\textbf{E},  \textbf{F}) or a larger dataset. The red and green curves represent the nullclines of $r$ and $v$, respectively. The dots represent the initial values for each trace, while the dashed lines correspond to the Neural ODE trajectories. The Neural ODE is prone to overfitting when noise is introduced in the training data, although it still preserves the overall dynamics. A larger dataset helps in recovering smoother nullclines.} 
    \label{fig:NeuralODE_montbrio}
\end{figure}

We then trained Neural ODEs using data generated by $10^4$ QIF neurons with a uniform stimulus (see \autoref{fig:NeuralODE_QIF}).
The data was partitioned using the first 400 points for training and predicting the remaining 1600 points. 
The results indicate that using derivatives dynamics, we can achieve a reliable understanding and prediction of the complex behavior of a network of spiking neurons, as illustrated in \autoref{fig:NeuralODE_QIF}. The emergent dynamics vary based on different parameter settings, resulting the stable node, stable focus, and bistable regime. See \autoref{fig:NeuralODE_loss_QIF} for the loss function in the training and test sets. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.10.eps}
    \caption{Reconstruction and extrapolation on QIF data with various parameters and dynamic regimes, using Neural ODEs. (\textbf{A}) Stable nodes, (\textbf{B}, \textbf{C}) Stable foci, (\textbf{D}, \textbf{E}) Bistability. The grey dots represent sparse  observations, blue lines represent predictions (400 points), and orange lines represent extrapolations (1600 points). We can see that our Neural ODE has learned the system dynamics and provides accurate predictions based on data generated at the microscopic level.} 
    \label{fig:NeuralODE_QIF}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

In the ever-evolving field of computational neuroscience, accurately estimating parameters that consistently govern the collective behavior of neural networks is a crucial endeavor, especially within the framework of recurrently coupled spiking neurons. In this study, we emphasize the use of mean-field (MF) theory to streamline the inference process for networks of spiking neurons. This choice is driven by the computational challenges in the calculation of the likelihood function---an essential ingredient for both frequentist and Bayesian inference methods---that becomes computationally prohibitive when attempting inference using these spiking networks in forward modeling.


The needs and objectives of researchers in the field of computational neuroscience are as diverse as the neural systems they aim to understand. Some studies may prioritize rapid point estimation through optimization, seeking quick outcomes to inform real-time decisions \citep{Vattikonda2021, Penas2023}. On the other hand, some studies find value in exploring the full distribution of parameters, which provides a nuanced understanding of parameter uncertainty for reliable decision making \citep{Hashemi2020, Jha2022}. This paper offers a comprehensive, yet non-exhaustive, benchmarking of the state-of-the-art inference methods applied to a MF model of spiking neurons (see \autoref{fig:ODEdata}, \autoref{fig:SDEdata}, and \autoref{fig:Missingdata}). Our comparative analyses offer practical guidance, assisting researchers in selecting the most suitable method for their specific datasets and research inquiries. Note that the comparison of computational cost and accuracy in parameter estimation can heavily depend on the selection of hyperparameters, such as population size in DE, warm-up phase in HMC, or the number of simulations and features in SBI. To make an unbiased assessment, we used optimal values for these hyperparameters in each algorithm, tailored to the dynamical model used in this study. Nevertheless, these optimal values may vary for different inverse problems, depending on parameter space and data dimensions, nonlinearity, sparsity, and the mapping function to measurements.

While optimization and Approximate Bayesian Computing methods can construct a confidence interval for the estimation based on bootstraping or on a threshold for accepting or rejecting the estimates, the results are highly dependent on the chosen threshold value \citep{Beaumont2002, Cranmer2020}. In contrast, Bayesian inference naturally provides uncertainty quantification by placing a distribution over parameters and treating them as random variable. Following Bayes' rule, this distribution is updated with evidence from observed data to form the posterior distribution, which furnishes comprehensive information for inference and prediction. 

Our results indicated that evolutionary algorithms for solving global optimization problems, such as DE, provide rapid and accurate point estimation of the true generative parameters when there is no dynamical noise present.
Challenges arise when using optimization methods in the presence of noisy data, mainly due to the lack of an efficient form of the objective function. The selection of the objective function plays a crucial role in determining the estimation through optimization methods \citep{Svensson2012, Hashemi2018}. The error explanation with distance metrics such as RMSE is limited in accurately capturing the underlying data generation process \citep{Baldy2023}. This is because when generative parameters remain unchanged but when dynamic noise is introduced, the time-series can show large fluctuations, resulting in deviations from the observed data. In particular, the presence of noise can easily lead to unreliable estimations, increasing the risk of overfitting, where the model fits to the noise rather than capturing the true underlying relationship. Consequently, it becomes more conspicuous to conduct inference using distributions in the Bayesian framework, particularly when dealing with dynamical noise.  Diagnosing of overfitting, as shown using MAP estimation (see \autoref{fig:SDEdata} and \autoref{fig:Missingdata}), can be better understood through uncertainty quantification. 

Furthermore, Bayesian inference can reveal the true relationships between parameters, capturing degeneracies in parameter space \citep{Edelman2001, Hashemi2023}. For example, when we assess the agreement between HMC and SBI across different scales (as shown in \autoref{fig:ReconstructedPhasePlane_and_corr}, \autoref{fig:ODE_joint_posterior}, \autoref{fig:SDE_joint_posterior}, and \autoref{fig:SDE_missingdata_joint_posterior}), it can be concluded that the persistent strong correlation between parameters $\eta$ and $J$ is inherent and not influenced by the inference procedure or model assumptions. This is in line with previous findings that have reported a strong and robust correlation between firing rates and synaptic weights across different brain states, environments and situations \citep{Buzsaki2014}. 


One of the main findings of this study is the effectiveness of deep neural networks in generating probability distributions for parameters of networks of spiking neurons. This approach outperforms other computational algorithms, such as MCMC, particularly in real-world applications involving missing data in bistable systems (see \autoref{fig:Missingdata}). The effectiveness of deep generative models for inference from the mechanistic model of networks of spiking neurons is confirmed by the robustness of the estimation under significant dynamic noise (\autoref{fig:NoiseSweep}, and \autoref{fig:SBI_SDE_Istep_RV_NoiseEstimation}), as well as the precise estimation of input current (\autoref{fig:SBI_stimulus}) and the consistency with linear stability analysis (\autoref{fig:SBI_PhaseDiagram}). However, it is important to acknowledge that the use of deep generative models can result in an overestimation of uncertainty and correlations between parameters. To address this challenge, incorporating time-delay embedding is an effective remedy (\autoref{fig:ReconstructedPhasePlane_and_corr}). 


Using high-performance computing, model simulations can be run independently, creating a large training dataset for training deep neural density estimators in SBI approach \citep{Hashemi2023}. In contrast, HMC is limited to embarrassingly parallel execution with only independent chains on computational nodes \citep{Hashemi2021}. Moreover, when dealing with bistability in the state-space representation, HMC methods require significant computational time to detect state transitions in the latent space (see~\autoref{tab:ODEdata}, \autoref{tab:SDEdata}, and \autoref{tab:Missingdata}) or need to be augmented with generative models such as normalizing flows \citep{Hoffman2019, Gabrie2022}. On the other hand, SBI offers efficient Bayesian estimation, even without detailed knowledge of the system's state-space representation. This aligns with findings from recent studies that highlight the efficiency of SBI across various challenging inverse problems \citep{Goncalves2020, Deistler2022, Boelts2022, Boelts2023, Hashemi2023, Lavanga2023, Yalccinkaya2023, Rabuffo2023, Sorrentino2023}. By benchmarking and addressing questions such as computational cost, uncertainty quantification, inter-dependency exploration, and data availability, we conclude that SBI is more efficient than alternatives in making informed choices from microscopic states to emergent dynamics at the macro scale. 

Note that our results should not rule out the use of HMC for dynamical mean-field models of spiking neurons. The implementation of HMC with parameterization tricks, adaptive integrators to solve ODEs/SDEs, and an effective initialization strategy in other tools such as Numpyro \citep{phan2019}, could significantly improve the computational cost of state-space estimation. Given that the main challenge lies in the complex posterior geometries \citep{Betancourt2017} and integration process, substantial time savings can be achieved through reparameterization techniques and optimizing the integrator. For instance, a careful manifold reparameterization to reorganize the model configuration space or replacing carry-over for-loops with a more efficient evaluation method \citep{jax2018} will facilitate exploration of the posterior distribution in terms of computational time and convergence diagnostics.

Moreover, our analyses were focused on a single neural population, with the assumption of heterogeneous all-to-all interaction between QIF neurons in the thermodynamic limit \citep{Montbrio_Pazo_Roxin}. Considering coupled excitatory and inhibitory populations and incorporating anatomical features of cortico-cortical connections would bring us closer to traversing scales, up to the whole-brain level \citep{Hashemi2020, Hashemi2021}. In essence, this presents a more challenging and sensitive inversion problem, and it is necessary to ascertain whether the competitive performance of SBI still holds in this context, especially considering the exploding number of parameters.

Considering the aforementioned points, extending the generality of our conclusions necessitates further investigation.
The first part of this work has focused on machine learning procedures for state-space modeling, some with a Bayesian twist to approximate the posterior distribution in one way or another. 
The alternative approach for the latter --that predominates in the identification of mean-field approximations to neuronal networks-- is based upon variational procedures, as used in Dynamic Causal Modeling (DCM; \cite{Friston2003}). DCM rests on minimizing the free energy, that is, the Kullback-Leibler divergence between the true and approximate posterior, minus the log-evidence (or marginal likelihood). This approach enables analytic solutions to the approximated posterior, eliminating the need for sampling, and provides a variational bound on model evidence for Bayesian model comparison \citep{Penny2012, Zeidman2023}. Hence, when the computed posterior is sufficiently accurate, free energy serves as a reliable approximation to the negative log-evidence. From the perspective of system identification \citep{Linderman2017}, DCM can be regarded as solving a triple estimation problem; namely, inferring the latent states, parameters, and precisions of a state-space model, with a known functional form \citep{Friston2010, Schiff2008}. Consequently, this approach to network inference can be interpreted as predictive coding \citep{Millidge2020}, which itself serves as a model or description of mean-field approximations to neural networks in the brain \citep{Friston2009}.

The main body of this work relies on the modeling assumption of mean-field approximation to spiking neurons. This assumption prompts questions regarding  the suitability of the chosen mean-field approximation. Such inquiries are relevant to system identification, which is often framed in terms of model selection, structure learning, or network discovery \citep{Friedman2003, Gershman2010, Seghier2013, Wipf2007}. For instance, one might explore the possibility  of replacing Eq. \eqref{eq:mpr} with a chaotic system (augmented with suitable exogenous inputs) and evaluate whether the mean-field model given by Eq. \eqref{eq:mpr} offers a superior explanation for the data compared to the chaotic system. Assessing model evidence can be achieved through Bayesian model comparison, by computing information criteria from a Bayesian perspective, such as the Widely Applicable Information Criterion \citep{Watanabe2010} and Expected Log Predictive Density using Leave-One-Out cross-validation \citep{Vehtari2016, Gelman2013}. In this context, a thorough investigation of approaches such as SBI is necessary in future studies. Nevertheless, HMC may be indispensable for achieving greater accuracy in Bayesian model comparison. 

Our study highlights the use of deep Neural ODEs in inferring vector fields at a macroscopic level, enabling the prediction of system dynamics from microscopic states. This approach has the potential to make interpretable predictions at larger scales from simulations at a detailed level, aiding in the prognosis and diagnosis of brain diseases. Recently, \cite{Sip2023} introduced a method using variational autoencoders for nonlinear dynamical system identification at the whole-brain level to infer both the neural mass model and the region- and subject-specific parameters from the functional data while respecting the known network structure. The scalability of Neural ODEs at the whole-brain network level remains to be investigated in future studies. In addition, symbolic regression applied to the outcomes from Neural ODEs may unveil closed-form equations for neural mass models, offering promising avenues for future research. This approach may lead to the discovery of concise data-driven mean-field representations of complex neural dynamics, contributing to our understanding of brain function.


In conclusion, this work highlights the improved accuracy and efficiency that deep learning techniques bring to the inference from networks of spiking neurons. It opens up exciting possibilities for future research in neural computation, where the trade-off between accuracy and uncertainty needs to be carefully considered. As we continue to explore the capabilities of SBI and Neural ODEs at larger scales, this study serves as a valuable step forward in our quest to unravel the complexities of neural networks and their computational mechanisms.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Information Sharing Statement}

All code is available \textcolor{black}{on} GitHub (\url{https://github.com/ins-amu/Inference_MFM}).

\section*{Acknowledgements}

This research has received funding from EU's Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreements No. 101147319 (EBRAINS 2.0 Project),  No. 101137289 (Virtual Brain Twin Project), and government grant managed by the Agence Nationale de la Recherche reference ANR-22-PESN-0012 (France 2030 program). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. We thank Lionel Kusch, Matthieu Gilson, and Spase Petkoski for fruitful discussions.

\section*{Author contributions}

Conceptualization: M.W., V.J., and M.H. Methodology: M.W., and M.H.  Software: \textcolor{black}{N.B, M.B.,} M.W., M.H.  Investigation: N.B., M.B., and M.H. Visualization: N.B., M.B., and M.H. Supervision: V.J., and  M.H. Funding acquisition: V.J. Writing - original draft: N.B., and M.H. Writing - review $\&$ editing: N.B, M.B,  M.W., V.J, and M.H.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\clearpage   
%\counterwithin{figure}{section} 

\setcounter{figure}{0}

\section*{Appendix}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S1.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{The phase-plane analysis of a mechanistic model of a network of all-to-all connected QIF neurons, using linear stability analysis. The stability of the system depends on the mean excitability ($\eta$) and synaptic weight ($J$), both normalized by the width of the input distribution ($\Delta$). (\textbf{A}) A single stable node corresponding to a low-activity state. (\textbf{B}) A single stable focus (spiral) corresponding to a high-activity state. (\textbf{C}) A bistability between low and high firing rates (stable node and stable focus, respectively). The upper section between $v$- and $r$-nulclines (in dark and light yellow, respectively) corresponds to an unstable focus. }
    \label{fig:MPR_Istep_phaseplanes}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S2.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Data features extracted from mean membrane potential data. Additional data features that are not represented on this diagram include skewness and kurtosis.}
    \label{fig:DataFeatures}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S3.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Sensitivity analysis on model parameters.  The profile likelihood is calculated using the root-mean-squared error (RMSE) between the observed and generated data, considering either a single parameter (represented by black curves) or multiple parameters to vary (represented by colored surfaces), while keeping the other parameters fixed. The true parameters are shown in gray, represented by a dashed vertical line (for a single parameter) or 2D coordinates (for multiple parameters).  The value of the Hessian matrix at the global minimum is displayed in the bar plot.}
    \label{fig:SensitivityAnalysis}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S4.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
            \caption{Paired posterior samples of model parameters inferred from deterministic data, using (\textbf{A}) HMC and (\textbf{B}) SBI. Samples do not exhibit significant pair-wise correlation in parameter couples ($\Delta$, $\eta$) and ($\Delta$, $J$). HMC manifests high linear correlation in sampling from joint parameters ($\eta$, $J$). In terms of uncertainty quantification, HMC offers a more informative posterior distribution compared to SBI. In terms of computational cost, SBI is approximately 60 orders of magnitude faster than HMC.}
    \label{fig:ODE_joint_posterior}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S5.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Paired posterior samples of model parameters inferred from noisy data, using (\textbf{A}) HMC and (\textbf{B}) SBI. Both algorithms provide uncorrelated samples for parameter couples ($\Delta$, $\eta$) and ($\Delta$, $J$) but exhibit the same level of strong linear correlation in sampling from joint parameters ($\eta$, $J$). Compared to HMC, SBI generates posteriors that more tightly center around the ground-truth parameters. Moreover, SBI remains approximately 8 orders of magnitude faster than HMC.}
    \label{fig:SDE_joint_posterior}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\linewidth]{Figs/NECO-00-000-0000-Figure.S6.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Posterior z-scores versus shrinkage, as a diagnostic for the reliability of Bayesian inference. An ideal Bayesian inference yields small z-scores (indicating less error) and high posterior shrinkage (indicating more contraction with respect to the prior distribution after learning from data). Therefore, their concentration lies in the right-bottom corner of the plot. When no data is missing, both HMC (red) and SBI (blue) perform near-optimally. However, SBI is significantly faster than HMC (at least 8 orders of magnitude). The posterior z-scores is defined as $z = \mathopen | \dfrac{\bar \theta-\theta^\ast}{\sigma_{post}}\mathclose|$, where $\bar \theta$ and $\theta^\ast$ are the posterior mean and the true values, respectively, whereas $\sigma_{prior}$, and $\sigma_{post}$ indicate the standard deviations of the prior and the posterior, respectively. The posterior shrinkage defined as $s= 1- \dfrac{\sigma^2_{post}}{\sigma^2_{prior}}$, where $\sigma_{prior}$, and $\sigma_{post}$ indicate the standard deviations of the prior and the posterior, respectively. 
    } 
    \label{fig:Zscores_Shrinkage_SDE}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S7.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{SBI over noisy data.  (\textbf{A}) The time-series prediction of membrane potential ($v$) and firing rate ($r$). (\textbf{B}) Estimated posteriors of parameters $\Delta$, $\eta$, $J$, and the intensity of dynamical noise $\sigma$. The true values are shown by vertical red lines. The priors and estimated posteriors using SBI are shown in green and blue colors, respectively. Given the low-dimensional data features of time-series, SBI is able to accurately and efficiently estimate the MF parameters including the dynamical noise in the system. }
    \label{fig:SBI_SDE_Istep_RV_NoiseEstimation}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S8.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Performance of SBI as a function of the number of simulations for the training step. (\textbf{A}) The tendency of shrinkage towards one indicates that all the posteriors are well-identified. While the shrinkage of the posterior is significantly improved when increasing the number of simulations from 1k to 10k, further increasing it beyond 100k only results in a marginal improvement. (\textbf{B}) The computational cost for SBI, which includes the simulation, training, and sampling steps, increases exponentially with respect to the number of simulations. }
    \label{fig:SBI_ZandShrink}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S9.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Paired posterior samples of model parameters inferred from noisy observation with missing data, using (\textbf{A}) HMC and (\textbf{B}) SBI, when only one variable (mean membrane potential $v$) is available. HMC samples deviate considerably from the true values, while SBI samples prove still reliable under such conditions, although accompanied with high correlation. Interestingly, SBI is approximately 68 orders of magnitude faster than HMC.}
    \label{fig:SDE_missingdata_joint_posterior}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S10.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Fit to the noisy observation with missing data, i.e., when only one variable (mean membrane potential $v$) is available: observation $v$ (top, black) and hidden $r$ (grey, bottom). The time-series fit provided by the different inference algorithms is plotted in colors.}
    \label{fig:SDEmissingdata_timeseries}
\end{figure}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S11.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Exemplifying observed ($v$ in blue and $r$ in red) and predicted ($v$ in cyan and $r$ in yellow) time-series using SBI on (\textbf{A}, \textbf{B}) Deterministic data, (\textbf{C}, \textbf{D}) Stochastic data, given the input as (\textbf{E}, \textbf{F}) Step current with $I(t)=I_0 \cdot \mathbf{1}{\text{stim}}(t)$, and sinusoidal current with $I(t)=\sin (\omega_0 t) \cdot \mathbf{1}{\text{stim}}(t)$, respectively.}
    \label{fig:SBI_Timeseries_ISin_IStep}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S12.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{Loss functions for the training and test data using Neural ODEs on MF model. (\textbf{A}, \textbf{B}) For the deterministic training set of size 100, the phase-space estimation is performed at the 22000th iteration. (\textbf{C}, \textbf{D}) Training set of size 100 with dynamical noise. (\textbf{E}, \textbf{F}) Training set of size 400 with dynamical noise.  The blue line represents the training error, while the orange line represents the test error. The vertical red line indicates the iteration at which a snapshot of the training is provided in the plot below.}
    \label{fig:NeuralODEs_Fit_traces_MPR}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figs/NECO-00-000-0000-Figure.S13.eps}
    \renewcommand{\thefigure}{S\arabic{figure}}
    \caption{The loss function by training Neural ODEs on QIF data. The train and test quadratic loss function is calculated, when the train set is made of (\textbf{A}) 300 first points and (\textbf{B}) 400 first points. In each case, $10,000$ iterations were used for training the model.}
    \label{fig:NeuralODE_loss_QIF}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

\begin{table}[p]
    \centering
    \begin{tabular}{lrrrrl}
    %\toprule
    {Method} & \multicolumn{2}{r}{RMSE parameters} & \multicolumn{2}{r}{RMSE time-series} & Running time \\
    {} &            mean &           std &             mean & std \\
    \midrule
    DE     &    5.256098e-16 &  1.662124e-15 &     6.757684e-19 &  1.114034e-18 &       0:0:51 \\
    PSO    &    7.181840e-01 &  8.508900e-01 &     3.221500e-04 &  2.887217e-04 &       0:0:35 \\
    BO     &    6.516364e-01 &  2.919346e-01 &     5.639526e-04 &  1.182884e-04 &      0:23:14 \\
    MAP    &    4.033716e+00 &  6.842649e-02 &     4.545021e-09 &  4.865735e-10 &       0:2:29 \\
    HMC    &    1.114323e-03 &  3.530420e-04 &     3.989852e-07 &  1.493006e-08 &     98:33:13 \\
    SBI    &    1.332644e-02 &  7.094355e-03 &     2.866951e-07 &  2.034953e-07 &      1:36:21 \\
    %\bottomrule
    \end{tabular}
\caption{Benchmark on deterministic data.}
\label{tab:ODEdata}
\end{table}


\begin{table}[p]
    \centering
    \begin{tabular}{lrrrrl}
    %\toprule
    {Method} & \multicolumn{2}{r}{RMSE parameters} & \multicolumn{2}{r}{RMSE time-series} & Running time \\
    {} &            mean &       std &             mean & std \\
    \midrule
    DE     &        0.672351 &  0.617302 &         0.000533 &  9.850079e-05 &       0:2:50 \\
    PSO    &        1.362540 &  0.852908 &         0.000717 &  1.116449e-04 &        0:1:8 \\
    BO     &        1.021078 &  0.519784 &         0.000888 &  8.232933e-05 &      0:15:36 \\
    MAP    &        3.883882 &  0.302616 &         0.000250 &  1.228436e-04 &       0:3:23 \\
    HMC    &        0.121416 &  0.081035 &         0.000004 &  1.427944e-08 &     15:56:28 \\
    SBI    &        0.052948 &  0.024310 &         0.000002 &  2.178518e-07 &      1:47:37 \\
    %\bottomrule
\end{tabular}
\caption{Benchmark on stochastic data.}
\label{tab:SDEdata}
\end{table}


\begin{table}[p]
    \centering
    \begin{tabular}{lrrrrl}
    %\toprule
    {Method} & \multicolumn{2}{r}{RMSE parameters} & \multicolumn{2}{r}{RMSE time-series} & Running time \\
    {} &            mean &       std &             mean & std \\
    \midrule
    DE & 0.426 & 0.388 & 0.218 & 0.102 & 0:4:7 \\
    PSO & 1.495 & 0.720 & 0.406 & 0.054 & 0:1:0 \\
    BO & 0.716 & 0.407 & 0.384 & 0.050 & 0:17:52 \\
    MAP & 3.539 & 0.029 & 1.838 & 0.185 & 0:0:30 \\
    HMC & 3.181 & 1.271 & 0.545 & 0.179 & 100:6:57 \\
    SBI & 0.427 & 0.296 & 0.609 & 0.213 & 1:27:34 \\
    %\bottomrule
    \end{tabular}
\caption{Benchmark on missing data. }
\label{tab:Missingdata}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{apalike}
\begin{thebibliography}{}

\bibitem[Abarbanel et~al., 1994]{Abarbanel}
Abarbanel, H.~D., Carroll, T., Pecora, L., Sidorowich, J., and Tsimring, L.~S.
  (1994).
\newblock Predicting physical variables in time-delay embedding.
\newblock {\em Physical Review E}, 49(3):1840.

\bibitem[Achard and De~Schutter, 2006]{Achard2006}
Achard, P. and De~Schutter, E. (2006).
\newblock Complex parameter landscape for a complex neuron model.
\newblock {\em PLoS computational biology}, 2(7):e94.

\bibitem[Alonso and Marder, 2019]{Alonso2019}
Alonso, L.~M. and Marder, E. (2019).
\newblock Visualization of currents in neural models with similar behavior and
  different conductance densities.
\newblock {\em Elife}, 8:e42722.

\bibitem[Amari, 1977]{Amari1977}
Amari, S.-i. (1977).
\newblock Dynamics of pattern formation in lateral-inhibition type neural
  fields.
\newblock {\em Biological cybernetics}, 27(2):77--87.

\bibitem[Andrieu et~al., 2003]{Andrieu2003}
Andrieu, C., De~Freitas, N., Doucet, A., and Jordan, M.~I. (2003).
\newblock An introduction to mcmc for machine learning.
\newblock {\em Machine learning}, 50(1):5--43.

\bibitem[Baldy et~al., 2023]{Baldy2023}
Baldy, N., Simon, N., Jirsa, V., and Hashemi, M. (2023).
\newblock Hierarchical bayesian pharmacometrics analysis of baclofen for
  alcohol use disorder.
\newblock {\em Machine Learning: Science and Technology}.

\bibitem[Bandyopadhyay et~al., 2021]{Bandyopadhyay2021}
Bandyopadhyay, A., Rabuffo, G., Calabrese, C., Gudibanda, K., Depannemaecker,
  D., Ivanov, A., Bernard, C., Jirsa, V.~K., and Petkoski, S. (2021).
\newblock Mean-field approximation of network of biophysical neurons driven by
  conductance-based ion exchange.
\newblock {\em bioRxiv}, pages 2021--10.

\bibitem[Banga and Balsa-Canto, 2008]{Banga2008}
Banga, J. and Balsa-Canto, E. (2008).
\newblock Parameter estimation and optimal experimental design.
\newblock {\em Essays Biochem}, 45:195--210.

\bibitem[Beaumont et~al., 2002]{Beaumont2002}
Beaumont, M.~A., Zhang, W., and Balding, D.~J. (2002).
\newblock Approximate bayesian computation in population genetics.
\newblock {\em Genetics}, 162(4):2025--2035.

\bibitem[Betancourt, 2017]{Betancourt2017}
Betancourt, M. (2017).
\newblock A conceptual introduction to hamiltonian monte carlo.
\newblock {\em arXiv preprint arXiv:1701.02434}.

\bibitem[Betancourt, 2013]{Betancourt2013}
Betancourt, M.~J. (2013).
\newblock Generalizing the no-u-turn sampler to riemannian manifolds.
\newblock {\em arXiv preprint arXiv:1304.1920}.

\bibitem[Bilo{\v{s}} et~al., 2021]{Bilovs2021}
Bilo{\v{s}}, M., Sommer, J., Rangapuram, S.~S., Januschowski, T., and
  G{\"u}nnemann, S. (2021).
\newblock Neural flows: Efficient alternative to neural odes.
\newblock {\em Advances in neural information processing systems},
  34:21325--21337.

\bibitem[Bishop, 2006]{Bishop}
Bishop, C.~M. (2006).
\newblock {\em Pattern Recognition and Machine Learning}.
\newblock Springer.

\bibitem[Bittner et~al., 2021]{Bittner2021}
Bittner, S.~R., Palmigiano, A., Piet, A.~T., Duan, C.~A., Brody, C.~D., Miller,
  K.~D., and Cunningham, J. (2021).
\newblock Interrogating theoretical models of neural computation with emergent
  property inference.
\newblock {\em Elife}, 10:e56265.

\bibitem[Blei et~al., 2017]{Blei2017}
Blei, D.~M., Kucukelbir, A., and McAuliffe, J.~D. (2017).
\newblock Variational inference: A review for statisticians.
\newblock {\em Journal of the American Statistical Association},
  112(518):859--877.

\bibitem[Boelts et~al., 2023]{Boelts2023}
Boelts, J., Harth, P., Gao, R., Udvary, D., Yanez, F., Baum, D., Hege, H.-C.,
  Oberlaender, M., and Macke, J.~H. (2023).
\newblock Simulation-based inference for efficient identification of generative
  models in computational connectomics.
\newblock {\em PLOS Computational Biology}, 19(9):1--28.

\bibitem[Boelts et~al., 2022]{Boelts2022}
Boelts, J., Lueckmann, J.-M., Gao, R., and Macke, J.~H. (2022).
\newblock Flexible and efficient simulation-based inference for models of
  decision-making.
\newblock {\em Elife}, 11:e77220.

\bibitem[Bradbury et~al., 2018a]{jax2018github}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q. (2018a).
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.

\bibitem[Bradbury et~al., 2018b]{jax2018}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q. (2018b).
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.

\bibitem[Brehmer, 2021]{Brehmer2021}
Brehmer, J. (2021).
\newblock Simulation-based inference in particle physics.
\newblock {\em Nature Reviews Physics}, 3(5):305--305.

\bibitem[Brehmer et~al., 2020]{Brehmer2020}
Brehmer, J., Louppe, G., Pavez, J., and Cranmer, K. (2020).
\newblock Mining gold from implicit models to improve likelihood-free
  inference.
\newblock {\em Proceedings of the National Academy of Sciences},
  117(10):5242--5249.

\bibitem[Brunton et~al., 2016]{Brunton2016}
Brunton, S.~L., Proctor, J.~L., and Kutz, J.~N. (2016).
\newblock Discovering governing equations from data by sparse identification of
  nonlinear dynamical systems.
\newblock {\em Proceedings of the national academy of sciences},
  113(15):3932--3937.

\bibitem[Buzs{\'a}ki and Mizuseki, 2014]{Buzsaki2014}
Buzs{\'a}ki, G. and Mizuseki, K. (2014).
\newblock The log-dynamic brain: how skewed distributions affect network
  operations.
\newblock {\em Nature Reviews Neuroscience}, 15(4):264--278.

\bibitem[Carpenter et~al., 2017]{Carpenter2017}
Carpenter, B., Gelman, A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M.,
  Brubaker, M., Guo, J., Li, P., and Riddell, A. (2017).
\newblock Stan : A probabilistic programming language.
\newblock {\em Journal of Statistical Software}, 76.

\bibitem[Chen et~al., 2018]{Chen2018}
Chen, R.~T., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K. (2018).
\newblock Neural ordinary differential equations.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[Cook et~al., 2022]{Cook2022}
Cook, B.~J., Peterson, A.~D., Woldman, W., and Terry, J.~R. (2022).
\newblock Neural field models: A mathematical overview and unifying framework.
\newblock {\em Mathematical Neuroscience and Applications}, 2.

\bibitem[Coombes and Byrne, 2018]{Coombes2018}
Coombes, S. and Byrne, A. (2018).
\newblock Next generation neural mass models.
\newblock In {\em Nonlinear dynamics in computational neuroscience}, pages
  1--16. Springer.

\bibitem[Cranmer et~al., 2020]{Cranmer2020}
Cranmer, K., Brehmer, J., and Louppe, G. (2020).
\newblock The frontier of simulation-based inference.
\newblock {\em Proceedings of the National Academy of Sciences},
  117(48):30055--30062.

\bibitem[David and Friston, 2003]{David2003}
David, O. and Friston, K.~J. (2003).
\newblock A neural mass model for meg/eeg:: coupling and neuronal dynamics.
\newblock {\em NeuroImage}, 20(3):1743--1755.

\bibitem[Dayan and Abbott, 2005]{Dayan2005}
Dayan, P. and Abbott, L.~F. (2005).
\newblock {\em Theoretical neuroscience: computational and mathematical
  modeling of neural systems}.
\newblock MIT press.

\bibitem[Deco et~al., 2008]{Deco2008}
Deco, G., Jirsa, V.~K., Robinson, P.~A., Breakspear, M., and Friston, K.
  (2008).
\newblock The dynamic brain: from spiking neurons to neural masses and cortical
  fields.
\newblock {\em PLoS computational biology}, 4(8):e1000092.

\bibitem[Deistler et~al., 2022]{Deistler2022}
Deistler, M., Goncalves, P.~J., and Macke, J.~H. (2022).
\newblock Truncated proposals for scalable and hassle-free simulation-based
  inference.
\newblock {\em Advances in Neural Information Processing Systems},
  35:23135--23149.

\bibitem[Duane et~al., 1987]{Duane1987}
Duane, S., Kennedy, A.~D., Pendleton, B.~J., and Roweth, D. (1987).
\newblock Hybrid monte carlo.
\newblock {\em Physics letters B}, 195(2):216--222.

\bibitem[Duncker et~al., 2019]{Duncker2019}
Duncker, L., Bohner, G., Boussard, J., and Sahani, M. (2019).
\newblock Learning interpretable continuous-time models of latent stochastic
  dynamical systems.
\newblock In {\em International Conference on Machine Learning}, pages
  1726--1734. PMLR.

\bibitem[Dupont et~al., 2019]{Dupont2019}
Dupont, E., Doucet, A., and Teh, Y.~W. (2019).
\newblock Augmented neural odes.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Durkan et~al., 2020]{Durkan2020}
Durkan, C., Murray, I., and Papamakarios, G. (2020).
\newblock On contrastive learning for likelihood-free inference.
\newblock In {\em International conference on machine learning}, pages
  2771--2781. PMLR.

\bibitem[Eberhart and Kennedy, 1995]{Eberhart1995}
Eberhart, R.~C. and Kennedy, J. (1995).
\newblock New optimizer using particle swarm theory.
\newblock {\em Proceedings of the 6th International Symposium on Micro Machine
  and Human Science}, pages 39--43.

\bibitem[Edelman and Gally, 2001]{Edelman2001}
Edelman, G.~M. and Gally, J.~A. (2001).
\newblock Degeneracy and complexity in biological systems.
\newblock {\em Proceedings of the National Academy of Sciences},
  98(24):13763--13768.

\bibitem[Floudas and Gounaris, 2009]{Floudas2009}
Floudas, C. and Gounaris, C.~E. (2009).
\newblock A review of recent advances in global optimization.
\newblock {\em J Glob Optim}, (45):3--38.

\bibitem[Friedman and Koller, 2004]{Friedman2003}
Friedman, N. and Koller, D. (2004).
\newblock Being bayesian about network structure. a bayesian approach to
  structure discovery in bayesian networks.
\newblock {\em Machine Learning}, 50:95--125.

\bibitem[Friston et~al., 2017]{Friston2017}
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., and Pezzulo, G.
  (2017).
\newblock Active inference: a process theory.
\newblock {\em Neural computation}, 29(1):1--49.

\bibitem[Friston and Kiebel, 2009]{Friston2009}
Friston, K. and Kiebel, S. (2009).
\newblock Predictive coding under the free-energy principle.
\newblock {\em Philosophical transactions of the Royal Society B: Biological
  sciences}, 364(1521):1211--1221.

\bibitem[Friston et~al., 2010]{Friston2010}
Friston, K., Stephan, K., Li, B., and Daunizeau, J. (2010).
\newblock Generalised filtering.
\newblock {\em Math. Probl. Eng.}, 2010:1--34.

\bibitem[Friston et~al., 2003]{Friston2003}
Friston, K.~J., Harrison, L., and Penny, W. (2003).
\newblock Dynamic causal modelling.
\newblock {\em NeuroImage}, 19(4):1273--1302.

\bibitem[Gabri{\'e} et~al., 2022]{Gabrie2022}
Gabri{\'e}, M., Rotskoff, G.~M., and Vanden-Eijnden, E. (2022).
\newblock Adaptive monte carlo augmented with normalizing flows.
\newblock {\em Proceedings of the National Academy of Sciences},
  119(10):e2109420119.

\bibitem[Gelman et~al., 2013]{Gelman2013}
Gelman, A., Hwang, J., and Vehtari, A. (2013).
\newblock Understanding predictive information criteria for bayesian models.

\bibitem[Gelman et~al., 1995]{BDA}
Gelman, A., Robert, C., Chopin, N., and Rousseau, J. (1995).
\newblock {\em {Bayesian} Data Analysis}.
\newblock CRC Press.

\bibitem[Gelman et~al., 2020]{Gelman2020}
Gelman, A., Vehtari, A., Simpson, D., Margossian, C.~C., Carpenter, B., Yao,
  Y., Kennedy, L., Gabry, J., Bürkner, P., and Modrák, M. (2020).
\newblock Bayesian workflow.

\bibitem[Gershman and Niv, 2010]{Gershman2010}
Gershman, S.~J. and Niv, Y. (2010).
\newblock Learning latent structure: carving nature at its joints.
\newblock {\em Curr Opin Neurobiol}, 20(2):251--256.

\bibitem[Gerstner and Kistler, 2002]{Gerstner2002}
Gerstner, W. and Kistler, W.~M. (2002).
\newblock {\em Spiking neuron models: Single neurons, populations, plasticity}.
\newblock Cambridge university press.

\bibitem[Gerstner et~al., 2014]{Gerstner2014}
Gerstner, W., Kistler, W.~M., Naud, R., and Paninski, L. (2014).
\newblock {\em Neuronal dynamics: From single neurons to networks and models of
  cognition}.
\newblock Cambridge University Press.

\bibitem[Gon{\c{c}}alves et~al., 2020]{Goncalves2020}
Gon{\c{c}}alves, P.~J., Lueckmann, J.-M., Deistler, M., Nonnenmacher, M.,
  \"Ocal, K., Bassetto, G., Chintaluri, C., Podlaski, W.~F., Haddad, S.~A.,
  Vogels, T.~P., Greenberg, D.~S., and Macke, J.~H. (2020).
\newblock Training deep neural density estimators to identify mechanistic
  models of neural dynamics.
\newblock {\em eLife}, 9:e56261.

\bibitem[Goyal and Benner, 2023]{Goyal2023}
Goyal, P. and Benner, P. (2023).
\newblock Neural ordinary differential equations with irregular and noisy data.
\newblock {\em Royal Society Open Science}, 10(7):221475.

\bibitem[Greenberg et~al., 2019]{Greenberg2019}
Greenberg, D., Nonnenmacher, M., and Macke, J. (2019).
\newblock Automatic posterior transformation for likelihood-free inference.
\newblock In {\em International Conference on Machine Learning}, pages
  2404--2414. PMLR.

\bibitem[Hashemi et~al., 2018]{Hashemi2018}
Hashemi, M., Hutt, A., Buhry, L., and Sleigh, J. (2018).
\newblock Optimal model parameter estimation from eeg power spectrum features
  observed during general anesthesia.
\newblock {\em Neuroinformatics}, 16(2):231--251.

\bibitem[Hashemi et~al., 2020]{Hashemi2020}
Hashemi, M., Vattikonda, A., Sip, V., Guye, M., Bartolomei, F., Woodman, M.~M.,
  and Jirsa, V.~K. (2020).
\newblock The {Bayesian} virtual epileptic patient: A probabilistic framework
  designed to infer the spatial map of epileptogenicity in a personalized
  large-scale brain model of epilepsy spread.
\newblock {\em NeuroImage}, 217:116839.

\bibitem[Hashemi et~al., 2023]{Hashemi2023}
Hashemi, M., Vattikonda, A.~N., Jha, J., Sip, V., Woodman, M.~M., Bartolomei,
  F., and Jirsa, V.~K. (2023).
\newblock Amortized bayesian inference on generative dynamical network models
  of epilepsy using deep neural density estimators.
\newblock {\em Neural Networks}, 163:178--194.

\bibitem[Hashemi et~al., 2021]{Hashemi2021}
Hashemi, M., Vattikonda, A.~N., Sip, V., Diaz-Pier, S., Peyser, A., Wang, H.,
  Guye, M., Bartolomei, F., Woodman, M.~M., and Jirsa, V.~K. (2021).
\newblock On the influence of prior information evaluated by fully bayesian
  criteria in a personalized whole-brain model of epilepsy spread.
\newblock {\em PLoS computational biology}, 17(7):e1009129.

\bibitem[Hertz, 2018]{Hertz2018}
Hertz, J.~A. (2018).
\newblock {\em Introduction to the theory of neural computation}.
\newblock Crc Press.

\bibitem[Hirsh et~al., 2021]{Hirsh2021}
Hirsh, S.~M., Ichinaga, S.~M., Brunton, S.~L., Nathan~Kutz, J., and Brunton,
  B.~W. (2021).
\newblock Structured time-delay models for dynamical systems with connections
  to frenet--serret frame.
\newblock {\em Proceedings of the Royal Society A}, 477(2254):20210097.

\bibitem[Hoffman et~al., 2019]{Hoffman2019}
Hoffman, M., Sountsov, P., Dillon, J.~V., Langmore, I., Tran, D., and
  Vasudevan, S. (2019).
\newblock Neutra-lizing bad geometry in hamiltonian monte carlo using neural
  transport.
\newblock {\em arXiv preprint arXiv:1903.03704}.

\bibitem[Hoffman and Gelman, 2014]{Hoffman2014}
Hoffman, M.~D. and Gelman, A. (2014).
\newblock The no-u-turn sampler: Adaptively setting path lengths in hamiltonian
  monte carlo.
\newblock {\em Journal of Machine Learning Research}, 15(47):1593--1623.

\bibitem[Hopfield, 1982]{Hopfield1982}
Hopfield, J.~J. (1982).
\newblock Neural networks and physical systems with emergent collective
  computational abilities.
\newblock {\em Proceedings of the national academy of sciences},
  79(8):2554--2558.

\bibitem[Hutt et~al., 2015]{Hutt2015}
Hutt, A., Hashemi, M., and beim Graben, P. (2015).
\newblock How to render neural fields more realistic.
\newblock {\em Validating Neuro-Computational Models of Neurological and
  Psychiatric Disorders}, pages 141--159.

\bibitem[Izhikevich, 2003]{Izhikevich2003}
Izhikevich, E.~M. (2003).
\newblock Simple model of spiking neurons.
\newblock {\em IEEE Transactions on neural networks}, 14(6):1569--1572.

\bibitem[Izhikevich, 2007]{Izhikevich2007}
Izhikevich, E.~M. (2007).
\newblock {\em Dynamical systems in neuroscience}.
\newblock MIT press.

\bibitem[Jha et~al., 2022]{Jha2022}
Jha, J., Hashemi, M., Vattikonda, A.~N., Wang, H., and Jirsa, V. (2022).
\newblock Fully bayesian estimation of virtual brain parameters with
  self-tuning hamiltonian monte carlo.
\newblock {\em Machine Learning: Science and Technology}, 3(3):035016.

\bibitem[Jirsa and Haken, 1996]{Jirsa1996}
Jirsa, V.~K. and Haken, H. (1996).
\newblock Field theory of electromagnetic brain activity.
\newblock {\em Physical review letters}, 77(5):960.

\bibitem[Juang, 1994]{Juang1994}
Juang, J.-N. (1994).
\newblock {\em Applied system identification}.
\newblock Prentice-Hall, Inc.

\bibitem[Kandel et~al., 2000]{Kandel2000}
Kandel, E.~R., Schwartz, J.~H., Jessell, T.~M., Siegelbaum, S., Hudspeth,
  A.~J., Mack, S., et~al. (2000).
\newblock {\em Principles of neural science}, volume~4.
\newblock McGraw-hill New York.

\bibitem[Kelley, 1999]{Kelley1999}
Kelley, C.~T. (1999).
\newblock {\em Iterative Methods for Optimization}.
\newblock North Carolina State University, Raleigh, North Carolina.

\bibitem[Kennedy and Eberhart, 1995]{Kennedy1995}
Kennedy, J. and Eberhart, R. (1995).
\newblock Particle swarm optimization.
\newblock 4:1942--1948 vol.4.

\bibitem[Kennel et~al., 1992]{Kennel1992}
Kennel, M.~B., Brown, R., and Abarbanel, H.~D. (1992).
\newblock Determining embedding dimension for phase-space reconstruction using
  a geometrical construction.
\newblock {\em Physical review A}, 45(6):3403.

\bibitem[Kim et~al., 2021]{Kim2021}
Kim, S., Ji, W., Deng, S., Ma, Y., and Rackauckas, C. (2021).
\newblock Stiff neural ordinary differential equations.
\newblock {\em Chaos: An Interdisciplinary Journal of Nonlinear Science},
  31(9).

\bibitem[Koppe et~al., 2019]{Koppe2019}
Koppe, G., Toutounji, H., Kirsch, P., Lis, S., and Durstewitz, D. (2019).
\newblock Identifying nonlinear dynamical systems via generative recurrent
  neural networks with applications to fmri.
\newblock {\em PLoS computational biology}, 15(8):e1007263.

\bibitem[Lavanga et~al., 2023]{Lavanga2023}
Lavanga, M., Stumme, J., Yalcinkaya, B.~H., Fousek, J., Jockwitz, C.,
  Sheheitli, H., Bittner, N., Hashemi, M., Petkoski, S., Caspers, S., et~al.
  (2023).
\newblock The virtual aging brain: Causal inference supports interhemispheric
  dedifferentiation in healthy aging.
\newblock {\em NeuroImage}, 283:120403.

\bibitem[Liepe et~al., 2014]{Liepe2014}
Liepe, J., Kirk, P., Filippi, S., Toni, T., Barnes, C.~P., and Stumpf, M.~P.
  (2014).
\newblock A framework for parameter estimation and model selection from
  experimental data in systems biology using approximate bayesian computation.
\newblock {\em Nature protocols}, 9(2):439--456.

\bibitem[Linderman et~al., 2017]{Linderman2017}
Linderman, S., Johnson, M., Miller, A., Adams, R., Blei, D., and Paninski, L.
  (2017).
\newblock Bayesian learning and inference in recurrent switching linear
  dynamical systems.
\newblock In {\em Artificial Intelligence and Statistics}, pages 914--922.
  PMLR.

\bibitem[Ljung, 1998]{Ljung1998}
Ljung, L. (1998).
\newblock System identification.
\newblock In {\em Signal analysis and prediction}, pages 163--173. Springer.

\bibitem[Lueckmann et~al., 2019]{Lueckmann2019}
Lueckmann, J.-M., Bassetto, G., Karaletsos, T., and Macke, J.~H. (2019).
\newblock Likelihood-free inference with emulator networks.
\newblock In {\em Symposium on Advances in Approximate Bayesian Inference},
  pages 32--53. PMLR.

\bibitem[Lueckmann et~al., 2021]{Lueckmann2021}
Lueckmann, J.-M., Boelts, J., Greenberg, D., Gon{\c{c}}alves, P., and Macke, J.
  (2021).
\newblock Benchmarking simulation-based inference.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 343--351. PMLR.

\bibitem[Lueckmann et~al., 2017]{Lueckmann2017}
Lueckmann, J.-M., Gon{\c{c}}alves, P.~J., Bassetto, G., {\"O}cal, K.,
  Nonnenmacher, M., and Macke, J.~H. (2017).
\newblock Flexible statistical inference for mechanistic models of neural
  dynamics.
\newblock {\em Advances in neural information processing systems}, 30.

\bibitem[Marder, 1998]{Marder1998}
Marder, E. (1998).
\newblock From biophysics to models of network function.
\newblock {\em Annual review of neuroscience}, 21(1):25--45.

\bibitem[McElreath, 2020]{Mcelreath2020}
McElreath, R. (2020).
\newblock {\em Statistical rethinking: A Bayesian course with examples in R and
  Stan}.
\newblock Chapman and Hall/CRC.

\bibitem[Mendes and Kell, 1998]{Mendes1998}
Mendes, P. and Kell, D. (1998).
\newblock Non-linear optimization of biochemical pathways: applications to
  metabolic engineering and parameter estimation.
\newblock {\em Bioinformatics (Oxford, England)}, 14(10):869--883.

\bibitem[Millidge et~al., 2020]{Millidge2020}
Millidge, B., Tschantz, A., and Buckley, C.~L. (2020).
\newblock Predictive coding approximates backprop along arbitrary computation
  graphs.

\bibitem[Miranda, 2018]{Miranda2018pyswarms}
Miranda, L.~J. (2018).
\newblock Pyswarms: a research toolkit for particle swarm optimization in
  python.
\newblock {\em Journal of Open Source Software}, 3(21):433.

\bibitem[M{\l}ynarski et~al., 2021]{Mlynarski2021}
M{\l}ynarski, W., Hled{\'\i}k, M., Sokolowski, T.~R., and Tka{\v{c}}ik, G.
  (2021).
\newblock Statistical analysis and optimality of neural systems.
\newblock {\em Neuron}, 109(7):1227--1241.

\bibitem[Montbri\'o et~al., 2015]{Montbrio_Pazo_Roxin}
Montbri\'o, E., Paz\'o, D., and Roxin, A. (2015).
\newblock Macroscopic description for networks of spiking neurons.
\newblock {\em Phys. Rev. X}, 5:021028.

\bibitem[Murphy, 2022]{Murphy2022}
Murphy, K.~P. (2022).
\newblock {\em Probabilistic machine learning: an introduction}.
\newblock MIT press.

\bibitem[Neal, 2010]{Neal2010}
Neal, R.~M. (2010).
\newblock {MCMC} using {Hamiltonian} dynamics.
\newblock {\em Handbook of Markov Chain Monte Carlo}, 54:113--162.

\bibitem[Nocedal and Wright, 1999]{Nocedal1999}
Nocedal, J. and Wright, S.~J. (1999).
\newblock {\em Numerical optimization}.
\newblock Springer.

\bibitem[Nogueira et~al., 2014]{Nogueira2014BO}
Nogueira, F. et~al. (2014).
\newblock Bayesian optimization: Open source constrained global optimization
  tool for python.

\bibitem[O'Leary et~al., 2015]{Leary2015}
O'Leary, T., Sutton, A.~C., and Marder, E. (2015).
\newblock Computational models in the age of large datasets.
\newblock {\em Current opinion in neurobiology}, 32:87--94.

\bibitem[Papamakarios and Murray, 2016]{Papamakarios2016}
Papamakarios, G. and Murray, I. (2016).
\newblock Fast $\varepsilon$-free inference of simulation models with bayesian
  conditional density estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1028--1036.

\bibitem[Papamakarios et~al., 2019a]{Papamakarios2019}
Papamakarios, G., Nalisnick, E., Rezende, D.~J., Mohamed, S., and
  Lakshminarayanan, B. (2019a).
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em arXiv preprint arXiv:1912.02762}.

\bibitem[Papamakarios et~al., 2017]{Papamakarios2017}
Papamakarios, G., Pavlakou, T., and Murray, I. (2017).
\newblock Masked autoregressive flow for density estimation.
\newblock {\em Advances in Neural Information Processing Systems}.

\bibitem[Papamakarios et~al., 2019b]{Papamakarios2019b}
Papamakarios, G., Sterratt, D., and Murray, I. (2019b).
\newblock Sequential neural likelihood: Fast likelihood-free inference with
  autoregressive flows.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 837--848. PMLR.

\bibitem[Penas et~al., 2023]{Penas2023}
Penas, D.~R., Hashemi, M., Jirsa, V.~K., and Banga, J.~R. (2023).
\newblock Parameter estimation in a whole-brain network model of epilepsy:
  comparison of parallel global optimization solvers.
\newblock {\em bioRxiv}, pages 2023--11.

\bibitem[Penny, 2012]{Penny2012}
Penny, W.~D. (2012).
\newblock Comparing dynamic causal models using {AIC}, {BIC} and free energy.
\newblock {\em Neuroimage}, 59(1):319--330.

\bibitem[Phan et~al., 2019]{phan2019}
Phan, D., Pradhan, N., and Jankowiak, M. (2019).
\newblock Composable effects for flexible and accelerated probabilistic
  programming in numpyro.
\newblock {\em arXiv preprint arXiv:1912.11554}.

\bibitem[Price, 1999]{Price1999}
Price, K. (1999).
\newblock {\em An Introduction to Differential Evolution in Corne, D., Dorigo,
  M. and Glover, F. (eds), New Ideas in Optimization}.
\newblock McGraw-Hill, London.

\bibitem[Prinz et~al., 2004]{Prinz2004}
Prinz, A.~A., Bucher, D., and Marder, E. (2004).
\newblock Similar network activity from disparate circuit parameters.
\newblock {\em Nature neuroscience}, 7(12):1345--1352.

\bibitem[Rabuffo et~al., 2023]{Rabuffo2023}
Rabuffo, G., Lokossou, H.-A., Li, Z., Ziaee-Mehr, A., Hashemi, M., Quilichini,
  P.~P., Ghestem, A., Arab, O., Esclapez, M., Verma, P., et~al. (2023).
\newblock On global brain reconfiguration after local manipulations.
\newblock {\em bioRxiv}, pages 2023--09.

\bibitem[Raue et~al., 2009]{Raue2009}
Raue, A., Kreutz, C., Maiwald, T., Bachmann, J., Schilling, M., and Timmer, U.
  K.~J. (2009).
\newblock Structural and practical identifiability analysis of partially
  observable dynamical models by exploiting the profile likelihood.
\newblock {\em Bioinformatics}, 25:1923--1929.

\bibitem[Rezende and Mohamed, 2015]{Rezende2015}
Rezende, D. and Mohamed, S. (2015).
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning (ICML)}, pages
  1530--1538. PMLR.

\bibitem[Schiff and Sauer, 2007]{Schiff2008}
Schiff, S.~J. and Sauer, T. (2007).
\newblock Kalman filter control of a model of spatiotemporal cortical dynamics.
\newblock 5(1):1.

\bibitem[Seghier and Friston, 2013]{Seghier2013}
Seghier, M.~L. and Friston, K.~J. (2013).
\newblock Network discovery with large {DCMs}.
\newblock {\em Neuroimage}, 68:181--191.

\bibitem[Shahriari et~al., 2015]{Shahriari2015}
Shahriari, B., Swersky, K., Wang, Z., Adams, R.~P., and De~Freitas, N. (2015).
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock {\em Proceedings of the IEEE}, 104(1):148--175.

\bibitem[Sip et~al., 2023]{Sip2023}
Sip, V., Hashemi, M., Dickscheid, T., Amunts, K., Petkoski, S., and Jirsa, V.
  (2023).
\newblock Characterization of regional differences in resting-state fmri with a
  data-driven network model of brain dynamics.
\newblock {\em Science Advances}, 9(11):eabq7547.

\bibitem[Snoek et~al., 2012]{Snoek2012}
Snoek, J., Larochelle, H., and Adams, R.~P. (2012).
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock 25.

\bibitem[Sorrentino et~al., 2023]{Sorrentino2023}
Sorrentino, P., Pathak, A., Ziaeemehr, A., Troisi~Lopez, E., Cipriano, L.,
  Romano, A., Sparaco, M., Quarantelli, M., Banerjee, A., Sorrentino, G.,
  et~al. (2023).
\newblock The virtual multiple sclerosis patient: on the clinical-radiological
  paradox.
\newblock {\em medRxiv}, pages 2023--12.

\bibitem[Stimberg et~al., 2019]{Stimberg2019}
Stimberg, M., Brette, R., and Goodman, D.~F. (2019).
\newblock Brian 2, an intuitive and efficient neural simulator.
\newblock {\em eLife}, 8:e47314.

\bibitem[Storn and Price, 1997]{Storn1997}
Storn, R. and Price, K. (1997).
\newblock Differential evolution -- a simple and efficient heuristic for global
  optimization over continuous spaces.
\newblock {\em Journal of Global Optimization}, 11(4):341--359.

\bibitem[Sussillo, 2014]{Sussillo2014}
Sussillo, D. (2014).
\newblock Neural circuits as computational dynamical systems.
\newblock {\em Current opinion in neurobiology}, 25:156--163.

\bibitem[Svensson et~al., 2012]{Svensson2012}
Svensson, C.-M., Coombes, S., and Peirce, J.~W. (2012).
\newblock Using {Evolutionary} {Algorithms} for {Fitting} {High}-{Dimensional}
  {Models} to {Neuronal} {Data}.
\newblock {\em Neuroinformatics}, 10(2):199--218.

\bibitem[Takens, 1981]{Takens2006}
Takens, F. (1981).
\newblock Detecting strange attractors in turbulence.
\newblock In {\em Dynamical Systems and Turbulence, Warwick 1980: proceedings
  of a symposium held at the University of Warwick 1979/80}, pages 366--381.
  Springer.

\bibitem[Tan et~al., 2023]{Tan2023}
Tan, E., Algar, S., Corr{\^e}a, D., Small, M., Stemler, T., and Walker, D.
  (2023).
\newblock Selecting embedding delays: An overview of embedding techniques and a
  new method using persistent homology.
\newblock {\em Chaos: An Interdisciplinary Journal of Nonlinear Science},
  33(3).

\bibitem[Tashkova et~al., 2011]{Tashkova2011}
Tashkova, K., Korosec, P., Silc, J., Todorovski, L., and Dzeroski, S. (2011).
\newblock Parameter estimation with bio-inspired meta-heuristic optimization:
  modeling the dynamics of endocytosis.
\newblock {\em BMC systems biology}, 5(1):159.

\bibitem[Tejero-Cantero et~al., 2020]{Tejero2020sbi}
Tejero-Cantero, A., Boelts, J., Deistler, M., Lueckmann, J.-M., Durkan, C.,
  Gon{\c{c}}alves, P.~J., Greenberg, D.~S., and Macke, J.~H. (2020).
\newblock Sbi--a toolkit for simulation-based inference.
\newblock {\em arXiv preprint arXiv:2007.09114}.

\bibitem[van~de Schoot et~al., 2021]{VanSchoot2021}
van~de Schoot, R., Depaoli, S., King, R., Kramer, B., M{\"a}rtens, K., Tadesse,
  M.~G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., et~al. (2021).
\newblock Bayesian statistics and modelling.
\newblock {\em Nature Reviews Methods Primers}, 1(1):1--26.

\bibitem[Vattikonda et~al., 2021]{Vattikonda2021}
Vattikonda, A.~N., Hashemi, M., Sip, V., Woodman, M.~M., Bartolomei, F., and
  Jirsa, V.~K. (2021).
\newblock Identifying spatio-temporal seizure propagation patterns in epilepsy
  using bayesian inference.
\newblock {\em Communications biology}, 4(1):1244.

\bibitem[Vehtari et~al., 2016]{Vehtari2016}
Vehtari, A., Gelman, A., and Gabry, J. (2016).
\newblock Practical bayesian model evaluation using leave-one-out
  cross-validation and waic.
\newblock {\em Statistics and Computing}, 27(5):1413--1432.

\bibitem[Virtanen et~al., 2020]{Virtanen2020scipy}
Virtanen, P., Gommers, R., Oliphant, T.~E., Haberland, M., Reddy, T.,
  Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., et~al.
  (2020).
\newblock Scipy 1.0: fundamental algorithms for scientific computing in python.
\newblock {\em Nature methods}, 17(3):261--272.

\bibitem[Watanabe, 2010]{Watanabe2010}
Watanabe, S. (2010).
\newblock Asymptotic equivalence of bayes cross validation and widely
  applicable information criterion in singular learning theory.
\newblock {\em Journal of Machine Learning Research}, 11(116):3571--3594.

\bibitem[Wieland et~al., 2021]{Wieland2021}
Wieland, F.-G., Hauber, A.~L., Rosenblatt, M., T{\"o}nsing, C., and Timmer, J.
  (2021).
\newblock On structural and practical identifiability.
\newblock {\em Current Opinion in Systems Biology}.

\bibitem[Wilson and Cowan, 1973]{Wilson1973}
Wilson, H.~R. and Cowan, J.~D. (1973).
\newblock A mathematical theory of the functional dynamics of cortical and
  thalamic nervous tissue.
\newblock {\em Kybernetik}, 13(2):55--80.

\bibitem[Wipf and Rao, 2007]{Wipf2007}
Wipf, D.~P. and Rao, B.~D. (2007).
\newblock An empirical bayesian strategy for solving the simultaneous sparse
  approximation problem.
\newblock {\em IEEE Transactions on Signal Processing}, 55(7):3704--3716.

\bibitem[Wiqvist et~al., 2021]{Wiqvist2021}
Wiqvist, S., Frellsen, J., and Picchini, U. (2021).
\newblock Sequential neural posterior and likelihood approximation.
\newblock {\em arXiv preprint arXiv:2102.06522}.

\bibitem[Yalccinkaya et~al., 2023]{Yalccinkaya2023}
Yalccinkaya, B.~H., Ziaeemehr, A., Fousek, J., Hashemi, M., Lavanga, M.,
  Solodkin, A., McIntosh, A.~R., Jirsa, V.~K., and Petkoski, S. (2023).
\newblock Personalized virtual brains of alzheimer's disease link dynamical
  biomarkers of fmri with increased local excitability.
\newblock {\em medRxiv}, pages 2023--01.

\bibitem[Yan et~al., 2019]{Yan2019}
Yan, H., Du, J., Tan, V.~Y., and Feng, J. (2019).
\newblock On robustness of neural ordinary differential equations.
\newblock {\em arXiv preprint arXiv:1910.05513}.

\bibitem[Zeidman et~al., 2023]{Zeidman2023}
Zeidman, P., Friston, K., and Parr, T. (2023).
\newblock A primer on variational laplace (vl).
\newblock {\em NeuroImage}, 279:120310.

\bibitem[Zhu et~al., 2022]{Zhu2022}
Zhu, A., Jin, P., Zhu, B., and Tang, Y. (2022).
\newblock On numerical integration in neural ordinary differential equations.
\newblock In {\em International Conference on Machine Learning}, pages
  27527--27547. PMLR.

\end{thebibliography}

\end{document}
